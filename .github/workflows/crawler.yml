name: KPI Crawler by Category (Every 5 Days)

on:
  workflow_dispatch:
  schedule:
    # Run every 5 days at 18:00 UTC (3 AM KST)
    - cron: '0 18 */5 * *'

jobs:
  crawl-by-category:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        category:
          - "공통자재"
          - "토목자재"
          - "건축자재"
          - "급배수"
          - "전기자재"
          - "석유화학"
          - "생활용품"
          - "재생재료"
      # --- 이 부분을 추가/수정합니다 ---
      max-parallel: 1 # 한 번에 하나의 카테고리만 처리하도록 설정
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r crawler/sites/requirements.txt

      - name: Install Playwright and its dependencies
        run: playwright install --with-deps

      - name: Run KPI Crawler
        run: python ./crawler/sites/kpi_crawler.py --major="${{ matrix.category }}" --start-year=2020 --start-month=1
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          KPI_USERNAME: ${{ secrets.KPI_USERNAME }}
          KPI_PASSWORD: ${{ secrets.KPI_PASSWORD }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          REDIS_TOKEN: ${{ secrets.REDIS_TOKEN }}
          UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
          UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
          FRONTEND_URL: https://materialinfo.vercel.app

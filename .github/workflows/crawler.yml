name: KPI Crawler by Category (Every 5 Days)

on:
  workflow_dispatch:
  schedule:
    # Run every 5 days at 18:00 UTC (3 AM KST)
    - cron: '0 18 */5 * *'

jobs:
  crawl-by-category:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        category:
          - "Í≥µÌÜµÏûêÏû¨"
          - "ÌÜ†Î™©ÏûêÏû¨"
          - "Í±¥Ï∂ïÏûêÏû¨"
          - "Í∏âÎ∞∞Ïàò"
          - "Ï†ÑÍ∏∞ÏûêÏû¨"
          - "ÏÑùÏú†ÌôîÌïô"
      # --- Ïù¥ Î∂ÄÎ∂ÑÏùÑ Ï∂îÍ∞Ä/ÏàòÏ†ïÌï©ÎãàÎã§ ---
      max-parallel: 1 # Ìïú Î≤àÏóê ÌïòÎÇòÏùò Ïπ¥ÌÖåÍ≥†Î¶¨Îßå Ï≤òÎ¶¨ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check file structure
        run: |
          echo "--- Current Directory ---"
          pwd
          echo "--- File List (Root) ---"
          ls -l
          echo "--- File List (All) ---"
          ls -R
          # End of file structure check

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r crawler/sites/requirements.txt

      - name: Install Playwright and its dependencies
        run: playwright install --with-deps

      - name: Install Supabase CLI
        run: |
          set -e
          curl -sL https://supabase.com/install/cli | bash
          echo "$HOME/.supabase/bin" >> $GITHUB_PATH
        shell: bash

      - name: Apply Supabase Migrations
        run: supabase db push
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

      - name: Debug Environment Variables
        run: |
          echo "üîç KPI_USERNAME=$KPI_USERNAME"
          echo "üîç SUPABASE_URL=$SUPABASE_URL"
          echo "üîç NEXT_PUBLIC_SUPABASE_URL=$NEXT_PUBLIC_SUPABASE_URL"
          echo "üîç SUPABASE_SERVICE_ROLE_KEY length: ${#SUPABASE_SERVICE_ROLE_KEY}"
          echo "üîç UPSTASH_REDIS_REST_URL=$UPSTASH_REDIS_REST_URL"  
          echo "üîç UPSTASH_REDIS_REST_TOKEN length: ${#UPSTASH_REDIS_REST_TOKEN}"

      - name: Run Crawler for ${{ matrix.category }}
        env:
          KPI_USERNAME: ${{ secrets.KPI_USERNAME }}
          KPI_PASSWORD: ${{ secrets.KPI_PASSWORD }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          REDIS_TOKEN: ${{ secrets.REDIS_TOKEN }}
          UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
          UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
          # ‚òÖ‚òÖ‚òÖ ÏïÑÎûò Ìïú Ï§ÑÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§ ‚òÖ‚òÖ‚òÖ
          FRONTEND_URL: https://materialinfo.vercel.app
        run: python ./crawler/sites/kpi_crawler.py --major="${{ matrix.category }}" --start-year=2020 --start-month=1

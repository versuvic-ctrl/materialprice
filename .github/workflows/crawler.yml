name: KPI Crawler by Category (Every 5 Days)

on:
  workflow_dispatch:
  schedule:
    # Run every 5 days at 18:00 UTC (3 AM KST)
    - cron: '0 18 */5 * *'

jobs:
  crawl-by-category:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        category:
          - "ê³µí†µìì¬"
          - "í† ëª©ìì¬"
          - "ê±´ì¶•ìì¬"
          - "ê¸‰ë°°ìˆ˜"
          - "ì „ê¸°ìì¬"
          - "ì„ìœ í™”í•™"
      # --- ì´ ë¶€ë¶„ì„ ì¶”ê°€/ìˆ˜ì •í•©ë‹ˆë‹¤ ---
      max-parallel: 1 # í•œ ë²ˆì— í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r crawler/sites/requirements.txt

      - name: Install Playwright and its dependencies
        run: playwright install --with-deps

      - uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Link Supabase Project
        run: supabase link --project-ref ${{ secrets.SUPABASE_PROJECT_REF }}
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}

      - name: Apply Supabase Migrations
        run: |
          set -e
          supabase db push
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

      - name: Debug Environment Variables
        run: |
          echo "ğŸ” KPI_USERNAME=$KPI_USERNAME"
          echo "ğŸ” SUPABASE_URL=$SUPABASE_URL"
          echo "ğŸ” NEXT_PUBLIC_SUPABASE_URL=$NEXT_PUBLIC_SUPABASE_URL"
          echo "ğŸ” SUPABASE_SERVICE_ROLE_KEY length: ${#SUPABASE_SERVICE_ROLE_KEY}"
          echo "ğŸ” UPSTASH_REDIS_REST_URL=$UPSTASH_REDIS_REST_URL"  
          echo "ğŸ” UPSTASH_REDIS_REST_TOKEN length: ${#UPSTASH_REDIS_REST_TOKEN}"

      - name: Run Crawler for ${{ matrix.category }}
        env:
          KPI_USERNAME: ${{ secrets.KPI_USERNAME }}
          KPI_PASSWORD: ${{ secrets.KPI_PASSWORD }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          REDIS_TOKEN: ${{ secrets.REDIS_TOKEN }}
          UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
          UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
          # â˜…â˜…â˜… ì•„ë˜ í•œ ì¤„ì„ ì¶”ê°€í•©ë‹ˆë‹¤ â˜…â˜…â˜…
          FRONTEND_URL: https://materialinfo.vercel.app
        run: python ./crawler/sites/kpi_crawler.py --major="${{ matrix.category }}" --start-year=2020 --start-month=1

      - name: Repair Supabase migration history
        run: npx supabase migration repair --status reverted 20251008050628 20251008112414 20251008112426 20251008112816 20251009072940 20251009074441 20251009090050 20251011093750 20251012032655 20251014162622 20251014174730 20251019071715 20251020125318 20251020131016 20251020131406 20251020140505 20251020150015 20251021140151
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}

      - name: Push Supabase migrations
        run: npx supabase db push
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}

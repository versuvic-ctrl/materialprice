name: Daily KPI Crawler by Category

on:
  workflow_dispatch: # Actions 탭에서 수동으로 실행할 수 있는 버튼 추가
  schedule:
    # 매일 19:00 UTC (한국 시간 기준 다음날 새벽 4시)에 자동 실행
    - cron: '0 19 * * *'

jobs:
  crawl-by-category:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        category:
          # 여기에 크롤링하고 싶은 대분류 이름을 정확하게 입력합니다.
          - "공통자재"
          - "토목자재"
          - "건축자재"
          - "급배수"
          - "전기자재"
          - "석유화학"
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check file structure
        run: |
          echo "--- Current Directory ---"
          pwd
          echo "--- File List (Root) ---"
          ls -l
          echo "--- File List (All) ---"
          ls -R
          # End of file structure check

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install playwright pandas python-dotenv supabase psutil redis

      - name: Install Playwright and its dependencies
        run: playwright install --with-deps

      - name: Run Crawler for ${{ matrix.category }}
        env:
          KPI_USERNAME: ${{ secrets.KPI_USERNAME }}
          KPI_PASSWORD: ${{ secrets.KPI_PASSWORD }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        # --major="공통자재" --start-year=2020 --start-month=1 형식으로 인자 전달
        run: python ./crawler/sites/kpi_crawler.py --major="${{ matrix.category }}" --start-year=2020 --start-month=1

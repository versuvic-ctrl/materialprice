name: KPI Crawler by Category (Every 5 Days)

on:
  workflow_dispatch:
  schedule:
    # Run every 5 days at 18:00 UTC (3 AM KST)
    - cron: '0 18 */5 * *'

jobs:
  crawl-by-category:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        category:
          - "공통자재"
          - "토목자재"
          - "건축자재"
          - "급배수"
          - "전기자재"
          - "석유화학"
      # --- 이 부분을 추가/수정합니다 ---
      max-parallel: 1 # 한 번에 하나의 카테고리만 처리하도록 설정
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r crawler/sites/requirements.txt

      - name: Install Playwright and its dependencies
        run: playwright install --with-deps

      - uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Link Supabase Project
        run: supabase link --project-ref ${{ secrets.SUPABASE_PROJECT_REF }}
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}

      - name: Apply Supabase Migrations
        run: |
          set -e
          supabase db push
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

      - name: Debug Environment Variables
        run: |
          echo "🔍 KPI_USERNAME=$KPI_USERNAME"
          echo "🔍 SUPABASE_URL=$SUPABASE_URL"
          echo "🔍 NEXT_PUBLIC_SUPABASE_URL=$NEXT_PUBLIC_SUPABASE_URL"
          echo "🔍 SUPABASE_SERVICE_ROLE_KEY length: ${#SUPABASE_SERVICE_ROLE_KEY}"
          echo "🔍 UPSTASH_REDIS_REST_URL=$UPSTASH_REDIS_REST_URL"  
          echo "🔍 UPSTASH_REDIS_REST_TOKEN length: ${#UPSTASH_REDIS_REST_TOKEN}"

      - name: Run Crawler for ${{ matrix.category }}
        env:
          KPI_USERNAME: ${{ secrets.KPI_USERNAME }}
          KPI_PASSWORD: ${{ secrets.KPI_PASSWORD }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          REDIS_TOKEN: ${{ secrets.REDIS_TOKEN }}
          UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
          UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
          # ★★★ 아래 한 줄을 추가합니다 ★★★
          FRONTEND_URL: https://materialinfo.vercel.app
        run: python ./crawler/sites/kpi_crawler.py --major="${{ matrix.category }}" --start-year=2020 --start-month=1

import os
import json
import re
import pandas as pd
from datetime import datetime
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from supabase import create_client, Client

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv("../../.env.local")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
SUPABASE_URL = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.environ.get("NEXT_PUBLIC_SUPABASE_ANON_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


def log(message: str, level: str = "INFO"):
    """ì‹¤í–‰ ê³¼ì • ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        message: ë¡œê·¸ ë©”ì‹œì§€
        level: ë¡œê·¸ ë ˆë²¨ (INFO, SUCCESS, ERROR, SUMMARY)
    """
    # ë¡œê·¸ ë ˆë²¨ë³„ ì¶œë ¥ ì œì–´
    if level == "SUMMARY":
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ“ {message}")
    elif level == "ERROR":
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ— {message}")
    elif level == "SUCCESS":
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ“ {message}")
    else:  # INFO
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")


class BaseDataProcessor(ABC):
    """ëª¨ë“  ì‚¬ì´íŠ¸ë³„ ë°ì´í„° ì²˜ë¦¬ê¸°ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.raw_data_list: List[Dict[str, Any]] = []
        self.processed_data_list: List[Dict[str, Any]] = []
    
    def add_raw_data(self, data: Dict[str, Any]):
        """íŒŒì‹±ëœ ì›ë³¸ ë°ì´í„°ë¥¼ ì¶”ê°€"""
        self.raw_data_list.append(data)
    
    @abstractmethod
    def transform_to_standard_format(self, raw_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì‚¬ì´íŠ¸ë³„ ì›ë³¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ
        
        Args:
            raw_data: ì‚¬ì´íŠ¸ë³„ ì›ë³¸ ë°ì´í„°
            
        Returns:
            í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            ê° í•­ëª©ì€ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•¨:
            {
                'major_category': str,
                'middle_category': str, 
                'sub_category': str,
                'specification': str,
                'unit': str,
                'region': str,
                'date': str,  # YYYY-MM-DD í˜•ì‹
                'price': int or None
            }
        """
        pass
    
    def to_dataframe(self) -> pd.DataFrame:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ì˜ Pandas DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.raw_data_list:
            return pd.DataFrame()
        
        self.processed_data_list = []
        
        # ê° ì›ë³¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        for raw_item in self.raw_data_list:
            transformed_items = self.transform_to_standard_format(raw_item)
            self.processed_data_list.extend(transformed_items)
        
        return pd.DataFrame(self.processed_data_list)
    
    def check_existing_data(self, major_category: str, middle_category: str, 
                           sub_category: str, specification: str, 
                           table_name: str = 'kpi_price_data') -> set:
        """Supabaseì—ì„œ ê¸°ì¡´ ë°ì´í„°ì˜ (ë‚ ì§œ, ì§€ì—­, ê°€ê²©, ê·œê²©) ì¡°í•©ì„ í™•ì¸"""
        try:
            log(f"        - ì¤‘ë³µ ì²´í¬ ì‹œì‘: {major_category} > {middle_category} > {sub_category} > {specification}")
            response = supabase.table(table_name).select(
                'date, region, price, specification'
            ).eq(
                'major_category', major_category
            ).eq(
                'middle_category', middle_category
            ).eq(
                'sub_category', sub_category
            ).eq(
                'specification', specification
            ).execute()
            
            if response.data:
                existing_data = set()
                for item in response.data:
                    # ë‚ ì§œ, ì§€ì—­, ê°€ê²©, ê·œê²© ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
                    combo = (item['date'], item['region'], str(item['price']), item['specification'])
                    existing_data.add(combo)
                log(f"        - ê¸°ì¡´ ë°ì´í„° ë°œê²¬: {len(existing_data)}ê°œ (ë‚ ì§œ-ì§€ì—­-ê°€ê²©-ê·œê²© ì¡°í•©)")
                return existing_data
            else:
                log("        - ê¸°ì¡´ ë°ì´í„° ì—†ìŒ: ì „ì²´ ì¶”ì¶œ í•„ìš”")
                return set()
                
        except Exception as e:
            log(f"        - ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return set()  # ì˜¤ë¥˜ ì‹œ ì „ì²´ ì¶”ì¶œ
    
    def filter_new_data_only(self, df: pd.DataFrame, table_name: str = 'kpi_price_data') -> pd.DataFrame:
        """ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•„í„°ë§ (ë‚ ì§œ-ì§€ì—­-ê°€ê²©-ê·œê²© ì¡°í•© ê¸°ì¤€)"""
        if df.empty:
            return df
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í•œ ë²ˆì— ì¡°íšŒ
        category_groups = df.groupby(['major_category', 'middle_category', 'sub_category', 'specification'])
        
        new_records = []
        total_records = len(df)
        skipped_count = 0
        
        for (major_cat, middle_cat, sub_cat, spec), group_df in category_groups:
            log(f"    - ì¤‘ë³µ ì²´í¬: {major_cat} > {middle_cat} > {sub_cat} > {spec}")
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (í•œ ë²ˆë§Œ)
            existing_data = self.check_existing_data(
                major_cat, middle_cat, sub_cat, spec, table_name
            )
            
            group_new_count = 0
            group_duplicate_count = 0
            
            # ê·¸ë£¹ ë‚´ ëª¨ë“  ë ˆì½”ë“œì— ëŒ€í•´ ì¤‘ë³µ ì²´í¬
            for _, record in group_df.iterrows():
                record_key = (record['date'], record['region'], str(record['price']), record['specification'])
                if record_key not in existing_data:
                    new_records.append(record.to_dict())
                    group_new_count += 1
                else:
                    group_duplicate_count += 1
                    skipped_count += 1
                    log(f"        - ì¤‘ë³µ SKIP: {record['date']} | {record['region']} | {record['price']}ì› | {record['specification']}")
            
            log(f"        - ê·¸ë£¹ ê²°ê³¼: ì‹ ê·œ {group_new_count}ê°œ, ì¤‘ë³µ {group_duplicate_count}ê°œ")
        
        if new_records:
            log(f"ğŸ“Š ì „ì²´ {total_records}ê°œ ì¤‘ ì‹ ê·œ {len(new_records)}ê°œ, ì¤‘ë³µ {skipped_count}ê°œ")
        else:
            log(f"ğŸ“Š ì „ì²´ {total_records}ê°œ ëª¨ë‘ ì¤‘ë³µ - ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
        
        return pd.DataFrame(new_records)
    
    def save_to_supabase(self, df: pd.DataFrame, table_name: str, check_duplicates: bool = True):
        """DataFrameì„ Supabase í…Œì´ë¸”ì— ì €ì¥"""
        if df.empty:
            log("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¤‘ë³µ ì²´í¬ê°€ í™œì„±í™”ëœ ê²½ìš° ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•„í„°ë§
        if check_duplicates:
            df = self.filter_new_data_only(df, table_name)
            if df.empty:
                log("ì €ì¥í•  ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
        
        try:
            records = df.to_dict(orient='records')
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ í•„í„°ë§
            valid_records = []
            for record in records:
                if self._is_valid_record(record):
                    # ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
                    record['date'] = self._normalize_date(record['date'])
                    valid_records.append(record)
                else:
                    log(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œì™¸: {record}")
            
            if not valid_records:
                log("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì–´ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            data, error = supabase.table(table_name).upsert(valid_records).execute()
            if error and error.message:
                log(f"âŒ Supabase ì €ì¥ ì‹¤íŒ¨: {error.message}")
            else:
                record_count = len(valid_records)
                log(f"ğŸ“Š {record_count}ê°œ ë°ì´í„° â†’ '{table_name}' í…Œì´ë¸” ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            log(f"Supabase ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    
    def _is_valid_record(self, record: Dict[str, Any]) -> bool:
        """ë ˆì½”ë“œì˜ ìœ íš¨ì„±ì„ ê²€ì¦"""
        required_fields = ['major_category', 'middle_category', 'sub_category', 
                          'specification', 'region', 'date']
        
        # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
        for field in required_fields:
            if field not in record or not record[field]:
                return False
        
        # ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
        if not self._is_valid_date_value(record['date']):
            return False
        
        # ê°€ê²© ìœ íš¨ì„± ê²€ì¦ (None í—ˆìš©)
        price = record.get('price')
        if price is not None and not isinstance(price, (int, float)):
            return False
        
        return True
    
    def _is_valid_date_value(self, date_value: Any) -> bool:
        """ë‚ ì§œ ê°’ì´ ìœ íš¨í•œì§€ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜"""
        if date_value is None:
            return False
        
        # ë¬¸ìì—´ì¸ ê²½ìš°
        if isinstance(date_value, str):
            date_str = date_value.strip()
            
            # ë¹ˆ ë¬¸ìì—´ ì²´í¬
            if not date_str:
                return False
            
            # ì§€ì—­ëª… íŒ¨í„´ ì²´í¬ (í•œêµ­ ì§€ì—­ëª…ë“¤)
            region_patterns = [
                'ê°•ì›', 'ê²½ê¸°', 'ê²½ë‚¨', 'ê²½ë¶', 'ê´‘ì£¼', 'ëŒ€êµ¬', 'ëŒ€ì „', 'ë¶€ì‚°',
                'ì„œìš¸', 'ì„¸ì¢…', 'ìš¸ì‚°', 'ì¸ì²œ', 'ì „ë‚¨', 'ì „ë¶', 'ì œì£¼', 'ì¶©ë‚¨', 'ì¶©ë¶',
                'ê°•â‘ ì›', 'ê°•â‘¡ì›', 'ê²½â‘ ê¸°', 'ê²½â‘¡ê¸°', 'ê²½â‘ ë‚¨', 'ê²½â‘¡ë‚¨', 'ê²½â‘ ë¶', 'ê²½â‘¡ë¶',
                'ê´‘â‘ ì£¼', 'ê´‘â‘¡ì£¼', 'ëŒ€â‘ êµ¬', 'ëŒ€â‘¡êµ¬', 'ëŒ€â‘ ì „', 'ëŒ€â‘¡ì „', 'ë¶€â‘ ì‚°', 'ë¶€â‘¡ì‚°',
                'ì„œâ‘ ìš¸', 'ì„œâ‘¡ìš¸', 'ì„¸â‘ ì¢…', 'ì„¸â‘¡ì¢…', 'ìš¸â‘ ì‚°', 'ìš¸â‘¡ì‚°', 'ì¸â‘ ì²œ', 'ì¸â‘¡ì²œ',
                'ì „â‘ ë‚¨', 'ì „â‘¡ë‚¨', 'ì „â‘ ë¶', 'ì „â‘¡ë¶', 'ì œâ‘ ì£¼', 'ì œâ‘¡ì£¼', 'ì¶©â‘ ë‚¨', 'ì¶©â‘¡ë‚¨',
                'ì¶©â‘ ë¶', 'ì¶©â‘¡ë¶'
            ]
            
            # ì§€ì—­ëª…ì´ í¬í•¨ëœ ê²½ìš° ë‚ ì§œê°€ ì•„ë‹˜
            for region in region_patterns:
                if region in date_str:
                    return False
            
            # ê¸°íƒ€ ì˜ëª»ëœ ê°’ ì²´í¬
            invalid_chars = ['ê°€', 'â‘ ', 'â‘¡', 'ê²©']
            if any(char in date_str for char in invalid_chars):
                return False
            
            # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYY-MM-DD ë˜ëŠ” YYYY/MM/DD)
            date_pattern = r'^\d{4}[-/]\d{1,2}[-/]\d{1,2}$'
            return bool(re.match(date_pattern, date_str))
        
        # datetime ê°ì²´ì¸ ê²½ìš°
        if hasattr(date_value, 'strftime'):
            return True
        
        return False
    
    def _normalize_date(self, date_value: Any) -> str:
        """ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
        if hasattr(date_value, 'strftime'):
            return date_value.strftime('%Y-%m-%d')
        elif isinstance(date_value, str):
            # ìŠ¬ë˜ì‹œë¥¼ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½
            return date_value.replace('/', '-')
        else:
            return str(date_value)
    
    def get_comparison_json(self) -> str:
        """ì›ë³¸ ë°ì´í„°ì™€ ê°€ê³µëœ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” JSON ìƒì„±"""
        processed_df = self.to_dataframe()
        
        # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        raw_data_converted = self._convert_datetime_to_string(self.raw_data_list)
        processed_data_converted = self._convert_datetime_to_string(
            processed_df.to_dict(orient='records'))
        
        return json.dumps({
            "raw_crawled_data": raw_data_converted,
            "pandas_processed_data": processed_data_converted
        }, ensure_ascii=False, indent=4)
    
    def _convert_datetime_to_string(self, obj: Any) -> Any:
        """datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ì¬ê·€ í•¨ìˆ˜"""
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {key: self._convert_datetime_to_string(value) 
                   for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_datetime_to_string(item) for item in obj]
        else:
            return obj


class KpiDataProcessor(BaseDataProcessor):
    """í•œêµ­ë¬¼ê°€ì •ë³´(KPI) ì‚¬ì´íŠ¸ ì „ìš© ë°ì´í„° ì²˜ë¦¬ê¸°"""
    
    def transform_to_standard_format(self, raw_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """KPI ì‚¬ì´íŠ¸ì˜ ì›ë³¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        transformed_items = []
        
        for spec_data in raw_data.get('spec_data', []):
            # spec_dataê°€ ì§ì ‘ price ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
            has_direct_price = (
                'spec_name' in spec_data and 'region' in spec_data and
                'date' in spec_data and 'price' in spec_data)
            
            if has_direct_price:
                transformed_items.append({
                    'major_category': raw_data['major_category_name'],
                    'middle_category': raw_data['middle_category_name'],
                    'sub_category': raw_data['sub_category_name'],
                    'specification': spec_data['spec_name'],
                    'unit': 'ì›/í†¤',  # KPI ê¸°ë³¸ê°’
                    'region': spec_data['region'],
                    'date': spec_data['date'],
                    'price': spec_data['price']
                })
            # ê¸°ì¡´ êµ¬ì¡° (prices ë°°ì—´ì´ ìˆëŠ” ê²½ìš°)
            else:
                for price_info in spec_data.get('prices', []):
                    price_value = None
                    if price_info.get('price'):
                        try:
                            price_value = int(price_info['price'].replace(',', ''))
                        except (ValueError, AttributeError):
                            price_value = None
                    
                    transformed_items.append({
                        'major_category': raw_data['major_category_name'],
                        'middle_category': raw_data['middle_category_name'],
                        'sub_category': raw_data['sub_category_name'],
                        'specification': spec_data['specification_name'],
                        'unit': spec_data.get('unit', 'ì›/í†¤'),
                        'region': price_info['region'],
                        'date': price_info['date'],
                        'price': price_value
                    })
        
        return transformed_items


class MaterialDataProcessor(BaseDataProcessor):
    """ë‹¤ë¥¸ ìì¬ ì‚¬ì´íŠ¸ìš© ë°ì´í„° ì²˜ë¦¬ê¸° (ì˜ˆì‹œ)"""
    
    def transform_to_standard_format(self, raw_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë‹¤ë¥¸ ì‚¬ì´íŠ¸ì˜ ì›ë³¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        ì´ ë©”ì„œë“œëŠ” ê° ì‚¬ì´íŠ¸ì˜ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        ì˜ˆì‹œë¡œ ê°„ë‹¨í•œ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
        transformed_items = []
        
        # ì˜ˆì‹œ: ë‹¤ë¥¸ ì‚¬ì´íŠ¸ì˜ ë°ì´í„° êµ¬ì¡°
        # {
        #     'category': 'ì² ê°•',
        #     'product_name': 'Hí˜•ê°•',
        #     'price_data': [
        #         {'location': 'ì„œìš¸', 'date': '2024-01-01', 'cost': 50000},
        #         ...
        #     ]
        # }
        
        category = raw_data.get('category', '')
        product_name = raw_data.get('product_name', '')
        
        for price_item in raw_data.get('price_data', []):
            transformed_items.append({
                'major_category': category,
                'middle_category': '',  # ì‚¬ì´íŠ¸ì— ë”°ë¼ ì¡°ì •
                'sub_category': product_name,
                'specification': product_name,
                'unit': 'ì›/í†¤',
                'region': price_item.get('location', ''),
                'date': price_item.get('date', ''),
                'price': price_item.get('cost')
            })
        
        return transformed_items


# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_data_processor(site_type: str) -> BaseDataProcessor:
    """ì‚¬ì´íŠ¸ íƒ€ì…ì— ë”°ë¥¸ ë°ì´í„° ì²˜ë¦¬ê¸° ìƒì„±
    
    Args:
        site_type: 'kpi', 'material', ë“±
        
    Returns:
        í•´ë‹¹ ì‚¬ì´íŠ¸ìš© ë°ì´í„° ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    processors = {
        'kpi': KpiDataProcessor,
        'material': MaterialDataProcessor,
        # ì¶”í›„ ë‹¤ë¥¸ ì‚¬ì´íŠ¸ ì¶”ê°€ ê°€ëŠ¥
    }
    
    processor_class = processors.get(site_type)
    if not processor_class:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‚¬ì´íŠ¸ íƒ€ì…: {site_type}")
    
    return processor_class()
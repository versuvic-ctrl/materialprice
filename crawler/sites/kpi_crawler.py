

import os
import asyncio
import json
import sys
import re
import psutil
from datetime import datetime
from dotenv import load_dotenv
import pandas as pd
from playwright.async_api import async_playwright
from data_processor import create_data_processor, log
from supabase import create_client, Client

# --- 1. ì´ˆê¸° ì„¤ì • ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ---
load_dotenv("../../.env.local")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
SUPABASE_URL = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.environ.get("NEXT_PUBLIC_SUPABASE_ANON_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


# --- 2. ì›¹ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ---


def check_running_crawler():
    """ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ í¬ë¡¤ëŸ¬ê°€ ìˆëŠ”ì§€ í™•ì¸"""
    current_pid = os.getpid()
    current_script = os.path.basename(__file__)
    
    running_crawlers = []
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            if proc.info['pid'] == current_pid:
                continue
                
            cmdline = proc.info['cmdline']
            if cmdline and any(current_script in cmd for cmd in cmdline):
                running_crawlers.append({
                    'pid': proc.info['pid'],
                    'cmdline': ' '.join(cmdline)
                })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    return running_crawlers


# --- 3. Playwright ì›¹ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ---
class KpiCrawler:
    """í•œêµ­ë¬¼ê°€ì •ë³´(KPI) ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬"""
    # <<< í¬í•¨í•  ì¤‘ë¶„ë¥˜ ë° ì†Œë¶„ë¥˜ ì„¤ì • >>>
    #
    #   - ì¤‘ë¶„ë¥˜ ì „ì²´ë¥¼ í¬í•¨í•˜ë ¤ë©´: "ì¤‘ë¶„ë¥˜ëª…": "__ALL__"
    #   - íŠ¹ì • ì†Œë¶„ë¥˜ë§Œ í¬í•¨í•˜ë ¤ë©´: "ì¤‘ë¶„ë¥˜ëª…": ["í¬í•¨í•  ì†Œë¶„ë¥˜ëª…1", "í¬í•¨í•  ì†Œë¶„ë¥˜ëª…2"]
    #   - ì§€ì •ë˜ì§€ ì•Šì€ ì¤‘ë¶„ë¥˜/ì†Œë¶„ë¥˜ëŠ” ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤
    #
    INCLUSION_LIST = {

    "ê³µí†µìì¬": {
        # --- ì•„ë˜ ëª©ë¡ì„ ì§ì ‘ ë³´ì‹œê³  í•„ìš” ì—†ëŠ” ì¤„ì„ ì‚­ì œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš” ---
        "ë´‰ê°•": [
            "ì´í˜•ì² ê·¼(ì´í˜•ë´‰ê°•)(1)",
            "ì´í˜•ì² ê·¼(ì´í˜•ë´‰ê°•)(2)",
            "íŠ¹ìˆ˜ì² ê·¼",
            "ì›í˜•ì² ê·¼(ì›í˜•ë´‰ê°•)",
            "ìŠ¤íŒŒì´ëŸ´ì² ê·¼",
            "ë‚˜ì„ ì² ì„ ",
            "PCê°•ë´‰"
        ],
        "í˜•ê°•": [
            "ã„±í˜•ê°•",
            "ã„·í˜•ê°•",
            "Ií˜•ê°•",
            "ë ˆì¼",
            "ì² ê³¨ë¸Œë ˆì´ìŠ¤",
            "TSC BEAM",
            "OCFT COLUMN",
            "Cí˜•ê°•",
            "HyFo BEAM",
            "ACT COLUMN",
            "ACT PILE",
            "Hí˜•ê°•",
            "ìš©ì ‘ê²½ëŸ‰Hí˜•ê°•"
        ],
        "ê°•íŒ": [
            "ì—´ì—°ê°•íŒ-1",
            "ì—´ì—°ê°•íŒ-2",
            "í›„íŒ-1",
            "í›„íŒ-2",
            "ëƒ‰ì—°ê°•íŒ-1",
            "ëƒ‰ì—°ê°•íŒ-2",
            "ì•„ì—°ë„ê°•íŒ-1",
            "ì•„ì—°ë„ê°•íŒ-2",
            "í”„ë¦°íŠ¸ê°•íŒ",
            "ì°©ìƒ‰ì•„ì—°ë„ê°•íŒ(ì¹¼ë¼ê°•íŒ)(1)-1",
            "ì°©ìƒ‰ì•„ì—°ë„ê°•íŒ(ì¹¼ë¼ê°•íŒ)(1)-2",
            "ì°©ìƒ‰ì•„ì—°ë„ê°•íŒ(ì¹¼ë¼ê°•íŒ)(2)",
        ],
        "ê°•ê´€": [
            "êµ¬ì¡°ìš©ê°•ê´€",
            "êµ¬ì¡°ìš©ê°ê´€"
        ],
        "íŠ¹ìˆ˜ê°•": [
            "êµ¬ì¡°ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€(1)",
            "êµ¬ì¡°ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€(2)",
            "êµ¬ì¡°ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€(3)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(1)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(2)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(3)-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(3)-2",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(4)-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•íŒ(4)-2",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì±„ë„-Hí˜•ê°•",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì•µê¸€",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤í™˜ë´‰",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì™€ì´ì–´ë¡œí”„",
            "ì£¼ì² í’ˆã†ì£¼ê°•í’ˆ",
            "íŠ¹ìˆ˜ê°•"
        ],
        "ë³¼íŠ¸ã†ë„ˆíŠ¸": [
            "ë„ˆíŠ¸",
            "ì ‘ì‹œë¨¸ë¦¬ë Œì§€ë³¼íŠ¸",
            "ë³´í†µ6ê°ë³¼íŠ¸",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤6ê°ë³¼íŠ¸-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤6ê°ë³¼íŠ¸-2",
            "ì½œë¼6ê°ë³¼íŠ¸(Gr 10.9)-1",
            "ì½œë¼6ê°ë³¼íŠ¸(Gr 10.9)-2",
            "ì½œë¼ë„ˆíŠ¸",
            "ì•„ì´ë³¼íŠ¸",
            "ì•„ì´ë„ˆíŠ¸",
            "ì „ì‚°ë³¼íŠ¸",
            "ìŠ¤í„°ë“œë³¼íŠ¸(B7)-1",
            "ìŠ¤í„°ë“œë³¼íŠ¸(B7)-2",
            "Uë³¼íŠ¸",
            "ì ˆì—°Uë³¼íŠ¸",
            "ì•µì»¤ë³¼íŠ¸(1)",
            "ì•µì»¤ë³¼íŠ¸(2)",
            "ì•µì»¤ë³¼íŠ¸(3)",
            "ì•µì»¤ë³¼íŠ¸(4)",
            "í’€ë¦¼ë°©ì§€ë„ˆíŠ¸"
        ],
        "ë¹„ì² ê¸ˆì†": [
            "ë™ì œí’ˆ(1)",
            "ë™ì œí’ˆ(2)",
            "ì•Œë£¨ë¯¸ëŠ„ì œí’ˆ(1)",
            "ì•Œë£¨ë¯¸ëŠ„ì œí’ˆ(2)",
            "ë¹„ì² ì§€ê¸ˆ(ééµåœ°ï¤Š)",
            "ì—°(ë‚©)ì œí’ˆ(é‰›è£½å“)"
        ],
        "ì‹œë©˜íŠ¸ã†ì½˜í¬ë¦¬íŠ¸": [
            "ë ˆë¯¸ì½˜-1",
            "ë ˆë¯¸ì½˜-2",
            "ì‹œë©˜íŠ¸-1",
            "ì‹œë©˜íŠ¸-2",
            "ì‹œë©˜íŠ¸-3",
            "ì‹œë©˜íŠ¸-4",
            "ë°©ìˆ˜Â·ë°©ì²­ì‹œë©˜íŠ¸",
            "íŠ¹ìˆ˜ë ˆë¯¸ì½˜",
            "ëª¨ë¥´í„°-1",
            "ëª¨ë¥´í„°-2",
            "íŠ¹ìˆ˜ì‹œë©˜íŠ¸ã†íƒ€ì¼ì‹œë©˜íŠ¸(1)",
            "íŠ¹ìˆ˜ì‹œë©˜íŠ¸ã†íƒ€ì¼ì‹œë©˜íŠ¸(2)",
            "íŠ¹ìˆ˜ì‹œë©˜íŠ¸ã†íƒ€ì¼ì‹œë©˜íŠ¸(3)",
            "ë“œë¼ì´ëª¨ë¥´í„°(1)",
            "ë“œë¼ì´ëª¨ë¥´í„°(2)"
        ],
        "ê°€ì„¤ìì¬": [
            "PDF (ë”ë¸” í”„ë ˆì„) íŒ¨ë„",
            "ë³µê³µíŒ ë° ì•ˆì „ë°œíŒ(1)",
            "ë³µê³µíŒ ë° ì•ˆì „ë°œíŒ(2)",
            "ë ˆë²¨ë´‰",
            "ìœ ë¡œí¼",
            "ë³µê³µíŒ",
            "ê°•ê´€ë¹„ê³„",
            "ê°•ê´€ì¨í¬íŠ¸",
            "ì¡°ë¦½ì‹í‹€ë¹„ê³„(ì´ë™ì‹í‹€ë¹„ê³„)",
        ],
    },

    "í† ëª©ìì¬": {
        "ì§€ìˆ˜íŒ": [
            "ê°•ì¬í† ë¥˜íŒ",
            "ì§€ìˆ˜íŒ"
        ],
        "ë°°ìˆ˜íŒ": [
            "ì°¨ìˆ˜íŒ(1)",
            "ì°¨ìˆ˜íŒ(2)",
            "ë°°ìˆ˜íŒ"
        ],
          "íŒŒì¼ë¥˜": [
            "ìŠ¤í¬ë¥˜íŒŒì¼",
            "ê³ ê°•ë„ì½˜í¬ë¦¬íŠ¸íŒŒì¼(PHC-Aì¢…)(1)",
            "ê³ ê°•ë„ì½˜í¬ë¦¬íŠ¸íŒŒì¼(PHC-B, Cì¢…)(2)",
            "PHC ë‘ë¶€ë³´ê°•ìì¬ ",
            "ì—ì½”ìŠ¤íŒŒì´ëŸ´",
            "PHCíŒŒì¼ ë‘ë¶€ë³´ê°•ìº¡(í•˜ë¶€íŒ ìŠ¤í‹¸ì œí’ˆ)",
            "PHCíŒŒì¼ ë‘ë¶€ë³´ê°•ìº¡(í•˜ë¶€íŒ P.Eì œí’ˆ)",
            "ê°•ê´€íŒŒì¼(1)",
            "ê°•ê´€íŒŒì¼(2)",
            "ë³µí•©ë§ëš(SCP)",
            "ë³µí•©ë§ëš(HCP)",
            "MSTRUT(ê³ ê°•ë„ê°•ê´€ë²„íŒ€ë³´)",
            "Uí˜•ì‹œíŠ¸íŒŒì¼(ì—´ê°„ì••ì—°ê°•ë„ë§ëš)",
            "ë‹¤ë™ì‹¬/ë‹¤ì¶• ê¸°ì´ˆ íŒŒì¼",
        ],
        "ë„ë¡œí¬ì¥ì¬": [
            "ì•„ìŠ¤íŒ”íŠ¸(1)",
            "ì•„ìŠ¤íŒ”íŠ¸(2)",
            "ì•„ìŠ¤íŒ”íŠ¸ì½˜í¬ë¦¬íŠ¸(1)",
            "ì•„ìŠ¤íŒ”íŠ¸ì½˜í¬ë¦¬íŠ¸(2)",
            "ì•„ìŠ¤íŒ”íŠ¸ì½˜í¬ë¦¬íŠ¸(3)",
            "í•˜ì´ë¸Œë¦¬ë“œ íˆ¬ìˆ˜ì½˜",
            "íˆ¬ìˆ˜ì„±ì½˜í¬ë¦¬íŠ¸ë„ë¡œí¬ì¥ì¬(1)",
            "íˆ¬ìˆ˜ì„±ì½˜í¬ë¦¬íŠ¸ë„ë¡œí¬ì¥ì¬(2)",
            "í™í¬ì¥ì¬(1)",
            "í™í¬ì¥ì¬(2)",
            "ë°•ì¸µí¬ì¥ì¬",
            "ë„ë¡œí¬ì¥ìš©ë³´ìˆ˜ì¬(1)",
            "ë„ë¡œí¬ì¥ìš©ë³´ìˆ˜ì¬(2)",
            "ë„ë¡œí¬ì¥ìš©ë³´ìˆ˜ì¬(3)",
            "ì½”ë¥´í¬í¬ì¥ì¬"
        ],
        "ê²½ê³„ë¸”ë¡": [
            "ì¸ì¡°í™”ê°•ì„ê²½ê³„ë¸”ë¡",
            "ì½˜í¬ë¦¬íŠ¸ê²½ê³„ë¸”ë¡(1)",
            "ì½˜í¬ë¦¬íŠ¸ê²½ê³„ë¸”ë¡(2)",
        ],
        "ë§¨í™€": [            "ì¡°ë¦½ì‹ë§¨í™€(1)",
            "ì¡°ë¦½ì‹ë§¨í™€(2)",
            "ë§¨í™€(1)",
            "ë§¨í™€(2)",
            "ë§¨í™€(3)",
        ],
        "ê·¸ë ˆì´íŒ…": [
            "ìŠ¤í‹¸ê·¸ë ˆì´íŒ…(1)",
            "ìŠ¤í‹¸ê·¸ë ˆì´íŒ…(2)",
        ],
        "ì² ê·¼ì½˜í¬ë¦¬íŠ¸ê´€": [
            "PCê´€",
            "ì² ê·¼ì½˜í¬ë¦¬íŠ¸ìˆ˜ë¡œê´€(1)",
            "ì² ê·¼ì½˜í¬ë¦¬íŠ¸ìˆ˜ë¡œê´€(2)",
        ]
    },

    "ê±´ì¶•ìì¬": {
        "ë²½ëŒ": [
            "ì½˜í¬ë¦¬íŠ¸ë²½ëŒ(ì‹œë©˜íŠ¸ë²½ëŒ)(1)",
            "ì½˜í¬ë¦¬íŠ¸ë²½ëŒ(ì‹œë©˜íŠ¸ë²½ëŒ)(2)",
            "ë‚´í™”ë²½ëŒ"
        ],
        "ê²½ëŸ‰ì½˜í¬ë¦¬íŠ¸íŒ": [
            "ì¡°ë¦½ì‹ë‚´ã†ì™¸ë²½íŒ¨ë„",
            "ì••ì¶œì„±í˜•ì‹œë©˜íŠ¸íŒ"
        ],
        "ë¯¸ì¥ì¬": [
            "ë¶ˆì—°ì„± ë¬´ê¸°ì§ˆê³„ ì ‘ì°©ì œ",
            "ë¬´ê¸°ì§ˆê³„ ë‚´ì™¸ì¥ ë§ˆê°ì¬",
            "ì™¸ë²½ë‹¨ì—´ë§ˆê°ì¬(1)",
            "ì™¸ë²½ë‹¨ì—´ë§ˆê°ì¬(2)",
            "í¼ë¼ì´íŠ¸",
            "ë‚´í™”í”¼ë³µì¬"
        ],
        "ì§€ë¶•ì¬": [
            "ìºë…¸í”¼ì§€ë¶•ì¬(ì°¨ì–‘)",
            "ì„¸ë¼ë¯¹ì‚¬ì´ë”©(ì™¸ë²½ì¬+ì§€ë¶•ì¬)",
            "ë³µí•©ê°•íŒ",
            "ì§•í¬"
        ],
        "ì ‘ì°©ì œ": [
            "ì ‘ì°©ì œ(1)",
            "ì ‘ì°©ì œ(2)"
        ],
        "ë„ë£Œ": [
            "ë°©í™”ã†ë°©ì—¼ã†ë‚´ì—´í˜ì¸íŠ¸(1)",
            "ë°©í™”ã†ë°©ì—¼ã†ë‚´ì—´í˜ì¸íŠ¸(2)",
            "ë°©ì²­í˜ì¸íŠ¸(1)",
            "ë°©ì²­í˜ì¸íŠ¸(2)",
            "ì¼€ì´ë¸”ë‚œì—°ë„ë£Œ",
            "ì„¸ë¼ë¯¹ì½”íŒ…ì œ(1)",
            "ì„¸ë¼ë¯¹ì½”íŒ…ì œ(2)",
            "ë‹¨ì—´í˜ì¸íŠ¸",
            "ì—í­ì‹œë„ë£Œ(1)",
            "ì—í­ì‹œë„ë£Œ(2)"
        ],
        "ë‚´ã†ì™¸ì¥íŒ¨ë„": [
            "ì¤€ë¶ˆì—° ì„±ëŠ¥ ë²½ë§ˆê°ì¬(ìƒì—…ìš©Â·ì£¼ê±°ìš©Â·ì‚¬ë¬´ìš©ê³µê°„)",
            "ì•Œë£¨ë¯¸ëŠ„íŒ¨ë„(1)",
            "ì•Œë£¨ë¯¸ëŠ„íŒ¨ë„(2)",
            "ì™¸ë²½Â·ì™¸ì¥ì•„ì—°ë„ê¸ˆê°•íŒ(ê¸ˆì†ì œíŒ¨ë„)",
            "ì¤€ë¶ˆì—°ì‹¤ë‚´ë§ˆê°íŒ¨ë„",
            "ì„¸ë¼ë¯¹íŒ¨ë„",
            "ì•„ì—°ë„ê°•íŒíŒ¨ë„",
            "ì™¸ì¥íŒ¨ë„(ê¸ˆì†ì œíŒ¨ë„)",
            "ì™¸ì¥íŒ¨ë„(ì„ì œ, íƒ€ì¼ ë‹¨ì—´íŒ¨ë„)",
        ],
        "ë³´ì˜¨ã†ë‹¨ì—´ì¬": [
            "ë¯¸ë„¤ë„ìš¸ë³´ì˜¨íŒ",
            "ì§„ê³µë‹¨ì—´ì¬(ë¯¸ë¼í´íˆíŠ¸)",
            "ì§„ê³µë‹¨ì—´ì¬(íŒŒì›Œë°±)",
            "ê¸€ë¼ìŠ¤ìš¸ë‹¨ì—´ë³´ì˜¨ì¬(1)",
            "ê¸€ë¼ìŠ¤ìš¸ë‹¨ì—´ë³´ì˜¨ì¬(2)",
            "ë°œí¬í´ë¦¬ìŠ¤í‹°ë ŒíŒ(1)",
            "ë°œí¬í´ë¦¬ìŠ¤í‹°ë ŒíŒ(ì••ì¶œ)(2)-1",
            "ë°œí¬í´ë¦¬ìŠ¤í‹°ë ŒíŒ(ì••ì¶œ)(2)-2",
            "ë°œí¬í´ë¦¬ìŠ¤í‹°ë ŒíŒ(ìŠ¤í‹°ë¡œí´)(3)",
            "ë°œí¬í´ë¦¬ìŠ¤í‹°ë ŒíŒ(ìŠ¤í‹°ë¡œí´)(4)",
            "ì¤€ë¶ˆì—° ê²½ì§ˆ í´ë¦¬ìš°ë ˆíƒ„ í¼ ë‹¨ì—´ì¬",
            "ê°€êµë°œí¬í´ë¦¬ì—í‹¸ë Œ ë³´ì˜¨íŒ (ì¹´ì´ë¡ )",
            "í´ë¦¬ì—ìŠ¤í„°ì„¬ìœ ë‹¨ì—´ì¬",
            "ì‹¬ì¬ ì¤€ë¶ˆì—° ë°œí¬í´ë¦¬ìŠ¤í‹°ë Œ ë‹¨ì—´ì¬(EPS)",
            "ê²½ì§ˆí´ë¦¬ìš°ë ˆíƒ„í¼ë‹¨ì—´ì¬(1)-1",
            "ê²½ì§ˆí´ë¦¬ìš°ë ˆíƒ„í¼ë‹¨ì—´ì¬(1)-2",
        ],
        "ì¡°ë¦½ì‹ê±´ë¬¼ì¬": [
            "ê²½ëŸ‰ì² ê³¨ì²œì¥ë¶€ì¬(1)",
            "ê²½ëŸ‰ì² ê³¨ì²œì¥ë¶€ì¬(2)",
            "ìƒŒë“œìœ„ì¹˜íŒ¨ë„(1)",
            "ìƒŒë“œìœ„ì¹˜íŒ¨ë„(2)",
            "ìƒŒë“œìœ„ì¹˜íŒ¨ë„(3)",
            "ì¹¸ë§‰ì´(1)",
            "ì¹¸ë§‰ì´(2)",
            "ì¹¸ë§‰ì´(3)",
        ],
    },

    "plumbingmbing": {
        "ë°°ê´€ì¬(â… )": [
            "ì¼ë°˜ë°°ê´€ìš©íƒ„ì†Œê°•ê´€(1)",
            "ì¼ë°˜ë°°ê´€ìš©íƒ„ì†Œê°•ê´€(2)",
            "ì••ë ¥ë°°ê´€ìš©íƒ„ì†Œê°•ê´€(ASTM A53)(1)",
            "ì••ë ¥ë°°ê´€ìš©íƒ„ì†Œê°•ê´€(SPPS 38)(2)",
            "ì—°ë£Œê°€ìŠ¤ë°°ê´€ìš©íƒ„ì†Œê°•ê´€",
            "ì†¡ìœ ê´€",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ë‚˜ì‚¬ì‹)",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ìš©ì ‘ì‹/í‘ê´€)-1",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ìš©ì ‘ì‹/í‘ê´€)-2",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ìš©ì ‘ì‹/ë°±ê´€)",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ìš©ì ‘ì‹/ë ˆë“€ìƒ¤/í‘ê´€)-1",
            "ê°•ê´€ì œê´€ì´ìŒì‡ (ìš©ì ‘ì‹/ë ˆë“€ìƒ¤/ë°±ê´€)-2",
            "ë‹¨ì¡°í”Œëœì§€",
            "ë‹¨ì—´ì´ì¤‘ë³´ì˜¨ê´€",
            "í´ë¦¬ì—í‹¸ë Œí”¼ë³µê°•ê´€-1",
            "í´ë¦¬ì—í‹¸ë Œí”¼ë³µê°•ê´€-2",
            "í´ë¦¬ì—í‹¸ë Œí”¼ë³µê°•ê´€ì´í˜•ê´€-1",
            "í´ë¦¬ì—í‹¸ë Œí”¼ë³µê°•ê´€ì´í˜•ê´€-2",
            "í´ë¦¬ì—í‹¸ë Œí”¼ë³µê°•ê´€ì´í˜•ê´€-3",
            "ë°°ê´€ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•ê´€(ì¼ë°˜ìš©)-1",
            "ë°°ê´€ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•ê´€(ì¼ë°˜ìš©)-2",
            "ë°°ê´€ìš©ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°•ê´€(ê³µì—…ìš©)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤Seamlessê°•ê´€-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤Seamlessê°•ê´€-2",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì£¼ë¦„ê´€",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤í”Œëœì§€",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€ì´ìŒì‡ (ìš©ì ‘ì‹)(1)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ê´€ì´ìŒì‡ (ìš©ì ‘ì‹)(2)",
            "ë™íŒŒì´í”„",
            "ë™ê´€ì´ìŒì‡ ",
            "ë³µí•©íŒŒì´í”„Â·ì´ìŒê´€",
            "FRP DUCT ì„±í˜•ê´€ ë° ì´ìŒê´€"
        ],
        "ë°°ê´€ì¬(â…¡)": [
            "í´ë¦¬ë¶€í‹¸ë ŒíŒŒì´í”„(PB)",
            "ê²½ì§ˆì—¼í™”ë¹„ë‹ê´€(PVCíŒŒì´í”„)",
            "PVCì´ìŒê´€(ìˆ˜ë„ìš©)",
            "PVC, CPVC íŒŒì´í”„ ë° ì´ìŒê´€(1)",
            "PVC, CPVC íŒŒì´í”„ ë° ì´ìŒê´€(2)",
            "ì¼ë°˜ìš©í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„",
            "ìˆ˜ë„ìš©í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„(1)-1",
            "ìˆ˜ë„ìš©í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„(1)-2",
            "ìˆ˜ë„ìš©í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„(2)",
            "í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„ã†ì´ìŒê´€(1)-1",
            "í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„ã†ì´ìŒê´€(1)-2",
            "í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„ã†ì´ìŒê´€(2)",
            "í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„ã†ì´ìŒê´€(3)-1",
            "í´ë¦¬ì—í‹¸ë ŒíŒŒì´í”„ã†ì´ìŒê´€(3)-2",
            "UHP PVDF SDR21/PN16 ë°°ê´€ì¬(1)",
            "UHP PVDF SDR21/PN16 ë°°ê´€ì¬(2)",
            "ECTFE SDR21 ë°°ê´€ì¬",
            "ìµìŠ¤íŒ¬ì…˜ì¡°ì¸íŠ¸",
        ],
        "ë°¸ë¸Œ": [
            "PVCë°¸ë¸Œ-1",
            "PVCë°¸ë¸Œ-2",
            "ì£¼ê°•ì œë°¸ë¸Œ",
            "ì£¼ì² ì œë°¸ë¸Œ",
            "ì²­ë™ì œë°¸ë¸Œ",
            "ë³¼ë°¸ë¸Œ(1)",
            "ë³¼ë°¸ë¸Œ(2)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë‹¨ì¡°ë°¸ë¸Œ(F304)(ì¼ë°˜ìš©)",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë‹¨ì¡°ë°¸ë¸Œ(F316)(ê°€ìŠ¤ìš©)",
            "ë‹¨ì¡°ë°¸ë¸Œ(A105)(ì¼ë°˜ìš©)",
            "ì»¨íŠ¸ë¡¤ë°¸ë¸Œ",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë³¼ë°¸ë¸Œ-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë³¼ë°¸ë¸Œ-2",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë°¸ë¸Œ",
            "ì£¼ê°•ì œë°¸ë¸Œ(CAST CARBON STEEL VALVE)",
            "ì²´í¬ë°¸ë¸Œ(íŒ)",
            "ë²„í„°í”Œë¼ì´ë°¸ë¸Œ(1)",
            "ë²„í„°í”Œë¼ì´ë°¸ë¸Œ(2)",
            "ë²„í„°í”Œë¼ì´ë°¸ë¸Œ(3)",
            "ë²„í„°í”Œë¼ì´ë°¸ë¸Œ(4)",
            "ìŠ¤íŒ€íŠ¸ë©",
            "ì˜¨ë„ì¡°ì ˆë°¸ë¸Œ",
            "ì•ˆì „ë°¸ë¸Œ(1)",
            "ì•ˆì „ë°¸ë¸Œ(2)",
            "ê°ì••ë°¸ë¸Œ",
            "ì„¸í¼ë ˆì´í„°",
            "ìŠ¤íŠ¸ë ˆì´ë„ˆ(1)",
            "ìŠ¤íŠ¸ë ˆì´ë„ˆ(2)",
            "ìë™ë°¸ë¸Œ",
        ],
        "íŒí”„ë¥˜": [
            "ì¶•ë¥˜íŒí”„",
            "ì‚¬ë¥˜íŒí”„",
            "ì…ì¶• ì‚¬ë¥˜ Â· ì¶•ë¥˜ íŒí”„",
            "ì–‘í¡ì…(ë³´ë¥˜íŠ¸)íŒí”„-1",
            "ì–‘í¡ì…(ë³´ë¥˜íŠ¸)íŒí”„-2",
            "ë‹¤ë‹¨ì™€ê¶Œ(ë³´ë¥˜íŠ¸)íŒí”„(1)",
            "ë‹¤ë‹¨ì™€ê¶Œ(ë³´ë¥˜íŠ¸)íŒí”„(2)",
            "ë‹¤ë‹¨ì™€ê¶Œ(íš¡í˜•í¸í¡ì…)íŒí”„",
            "ë‹¨ë‹¨ì™€ê¶Œ(ë³´ë¥˜íŠ¸)íŒí”„(1)",
            "ë‹¨ë‹¨ì™€ê¶Œ(ë³´ë¥˜íŠ¸)íŒí”„(2)",
            "ë‹¤ë‹¨ì™€ê¶Œ(í„°ë¹ˆ)íŒí”„",
            "ì •ëŸ‰íŒí”„-1",
            "ì •ëŸ‰íŒí”„-2",
            "ë‚´ì‚°íŒí”„",
            "ë¶€ìŠ¤íƒ€(ê°€ì••)íŒí”„(1)-1",
            "ë¶€ìŠ¤íƒ€(ê°€ì••)íŒí”„(1)-2",
            "ë¶€ìŠ¤íƒ€(ê°€ì••)íŒí”„(2)-1",
            "ë¶€ìŠ¤íƒ€(ê°€ì••)íŒí”„(2)-2",
            "ìˆ˜ì¤‘ëª¨í„°íŒí”„(1)",
            "ìˆ˜ì¤‘ëª¨í„°íŒí”„(2)",
            "ì¸ë¼ì¸íŒí”„(1)",
            "ì¸ë¼ì¸íŒí”„(2)",
            "ì…í˜•ë‹¤ë‹¨íŒí”„(1)",
            "ì…í˜•ë‹¤ë‹¨íŒí”„(2)",
            "ìë™íŒí”„(1)",
            "ìë™íŒí”„(2)",
            "íŠœë¸Œã†í˜¸ìŠ¤íŒí”„",
            "ì§„ê³µíŒí”„"
        ],
        "ì¡°ã†íƒ±í¬ë¥˜": [
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë¬¼íƒ±í¬(1)-1",
            "ìŠ¤í…Œì¸ë¦¬ìŠ¤ë¬¼íƒ±í¬(1)-2",
            "FRPì•½í’ˆíƒ±í¬",
            "FRPë¬¼íƒ±í¬-1",
            "FRPë¬¼íƒ±í¬-2",
            "PEì¼€ë¯¸ì¹¼íƒ±í¬",
            "PEë¬¼íƒ±í¬",
            "FRPì •í™”ì¡°(1)",
            "FRPì •í™”ì¡°(2)",
        ],
        "íŒŒì´í”„ì»¤ë²„": [
            "ê°€êµë°œí¬í´ë¦¬ì—í‹¸ë Œë³´ì˜¨ì¬(ì¹´ì´ë¡ )-1",
            "ê°€êµë°œí¬í´ë¦¬ì—í‹¸ë Œë³´ì˜¨ì¬(ì¹´ì´ë¡ )-2",
            "ìœ ë¦¬ì„¬ìœ ë³´ì˜¨ì¬",
            "ì•„ë§ˆì ¤ì—ì–´ë¡œì ¤ë‹¨ì—´ì¬",
            "ë¯¸ë„¤ë„ìš¸ë³´ì˜¨ì¬",
            "ê³ ë¬´ë°œí¬ë³´ì˜¨ì¬(ì¹´ì´í”Œë ‰ìŠ¤)-1",
            "ê³ ë¬´ë°œí¬ë³´ì˜¨ì¬(ì¹´ì´í”Œë ‰ìŠ¤)-2",
            "AESìš¸ ë¶ˆì—°ì„±ë‹¨ì—´ì¬",
            "HITLIN PIPE COVER HGë¹„ë°œìˆ˜ TYPE ë³´ì˜¨ì¬-1",
            "HITLIN PIPE COVER HGë¹„ë°œìˆ˜ TYPE ë³´ì˜¨ì¬-2",
            "HITLIN PIPE COVER HGë°œìˆ˜ TYPE ë³´ì˜¨ì¬-1",
            "HITLIN PIPE COVER HGë°œìˆ˜ TYPE ë³´ì˜¨ì¬-2",
            "HITLIN PIPE COVER  HGAë¹„ë°œìˆ˜ TYPE ë³´ì˜¨ì¬-1",
            "HITLIN PIPE COVER  HGAë¹„ë°œìˆ˜ TYPE ë³´ì˜¨ì¬-2",
            "ë½í‚¹ì‹ë³´ì˜¨ì™¸ì¥ì»¤ë²„(íŒŒì´í”„ë³´ì˜¨)",
            "ë½í‚¹ì‹ë³´ì˜¨ì™¸ì¥ì»¤ë²„(ì—˜ë³´ë³´ì˜¨)",
            "ë½í‚¹ì‹ë³´ì˜¨ì™¸ì¥ì»¤ë²„(ë°¸ë¸Œë³´ì˜¨)",
            "í›„í¬ì‹ ë³´ì˜¨ì™¸ì¥ì¡°ë¦½ì¹´ë°”(íŒŒì´í”„ë³´ì˜¨)",
            "í›„í¬ì‹ ë³´ì˜¨ì™¸ì¥ì¡°ë¦½ì¹´ë°”(ì—˜ë³´ë³´ì˜¨)",
            "í›„í¬ì‹ ë³´ì˜¨ì™¸ì¥ì¡°ë¦½ì¹´ë°”(ë°¸ë¸Œë³´ì˜¨)"
        ]
    },

    "ì „ê¸°ìì¬": {
        "ì ˆì—°ì „ì„ ": [
            "ë‚´ì—´ë¹„ë‹ì ˆì—°ì „ì„ (HIV)",
            "ë‚œì—°PVCì ˆì—°ì ‘ì§€ìš©ì „ì„ (F-GV)",
            "ì €ë…ë‚œì—°ê°€êµí´ë¦¬ì˜¬ë ˆí•€ì ˆì—°ì „ì„ (HFIX)",
            "ë‚œì—°ì„±í´ë¦¬í”„ë ‰ìŠ¤êµ¬ì¶œì„ (MLFC)",
            "ì˜¥ì™¸ìš©ë¹„ë‹ì ˆì—°ì „ì„ (OW)",
            "ì¸ì…ìš©ë¹„ë‹ì ˆì—°ì „ì„ (DV)",
            "ê³ ë¬´ì ˆì—°ìº¡íƒ€ì´ì–´ì¼€ì´ë¸”(PNCT)(1)",
            "ê³ ë¬´ì ˆì—°ìº¡íƒ€ì´ì–´ì¼€ì´ë¸”(PNCT)(2)",
            "ë¹„ë‹ì ˆì—°ë¹„ë‹ìº¡íƒ€ì´ì–´ì¼€ì´ë¸”(VCT)(1)",
            "ë¹„ë‹ì ˆì—°ë¹„ë‹ìº¡íƒ€ì´ì–´ì¼€ì´ë¸”(VCT)(2)",
            "ì „ê¸°ê¸°ê¸°ìš©ë¹„ë‹ì ˆì—°ì „ì„ (KIV)",
            "ê¸°êµ¬ìš©ë¹„ë‹ì½”ë“œ",
            "ê³ ë¬´ì½”ë“œ(CTF)",
            "í´ë¡œë¡œí”„ë Œí”¼ë³µì¸ì¶œì„ (CRë°°ì„ )",
            "ìš©ì ‘ìš©ì¼€ì´ë¸”(WCT)"
        ],
        "ì „ë ¥ì¼€ì´ë¸”": [
            "ì ˆì—°ë‚œì—°PVCì‹œìŠ¤ì¼€ì´ë¸”(FW-CV, TFR-CV)",
            "í•©ê¸ˆ ì¼€ì´ë¸”(í•˜ì´ë™ìŠ¤, HiRaCS)",
            "ì ˆì—°ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤ì¼€ì´ë¸”(HFCO)",
            "ìˆ˜ë°€í˜•ì €ë…ì„±ë‚œì—°ë™ì‹¬ì¤‘ì„±ì„ ì¼€ì´ë¸”(FR-CN/CO-W)",
            "ìˆ˜ë°€í˜•ë™ì‹¬ì¤‘ì„±ì„ ì¼€ì´ë¸”(CN/CV-W)"
        ],
        "ì œì–´ìš©ì¼€ì´ë¸”": [
            "ì ˆì—°ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤ì œì–´ìš©ì¼€ì´ë¸”(HFCCO)",
            "ì ˆì—°ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤ì°¨íì œì–´ìš©ì¼€ì´ë¸”(HFCCO-Sã†SB)",
            "ì ˆì—°ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤ì•Œë£¨ë¯¸ëŠ„ë§ˆì¼ë¼í…Œì´í”„ì œì–´ìš©ì¼€ì´ë¸”(HFCCO-AMSã†I/C AMS)",
            "ì ˆì—°ë‚œì—°ì‹œìŠ¤ì œì–´ì¼€ì´ë¸”(FW-CVV)",
            "ì ˆì—°ë‚œì—°ì‹œìŠ¤ì œì–´ì°¨íì¼€ì´ë¸”(FW-CVV-Sã†SB)",
            "ì ˆì—°ë‚œì—°ì‹œìŠ¤ì•Œë£¨ë¯¸ëŠ„ë§ˆì¼ë¼í…Œì´í”„ì°¨íì œì–´ì¼€ì´ë¸”(FW-CVV-AMSã†I/C AMS)"
        ],
        "ì†Œë°©ìš©ì¼€ì´ë¸”": [
            "ë‚œì—°PVCì‹œìŠ¤íŠ¸ë ˆì´ìš©ë‚´í™”ì¼€ì´ë¸”(TFR-8)",
            "ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤íŠ¸ë ˆì´ìš©ë‚œì—°ë‚´í™”ì¼€ì´ë¸”(NFR-8)",
            "ë‚œì—°PVCì‹œìŠ¤í™”ì¬ê²½ë³´ìš©ë‚´ì—´ì¼€ì´ë¸”(TFR-3)",
            "ì €ë…ì„±ë‚œì—°í´ë¦¬ì˜¬ë ˆí•€ì‹œìŠ¤í™”ì¬ê²½ë³´ìš©ë‚´ì—´ì¼€ì´ë¸”(NFR-3)",
            "ì „ì„ ê´€ì¼ì²´í˜•ë‚´í™”ì „ì„ "
        ],
        "í†µì‹ ìš©ì¼€ì´ë¸”": [
            "ë¹„ë‹ì ˆì—°ë¹„ë‹ì‹œìŠ¤ì „í™”ìš©êµ­ë‚´ì¼€ì´ë¸”",
            "í´ë¦¬ì—í‹¸ë Œì ˆì—°ë¹„ë‹ì‹œìŠ¤ë‚´ìŒì¼€ì´ë¸”(CPEV)",
            "PCM(DS1)ì¼€ì´ë¸”",
            "ê´‘ì¼€ì´ë¸”",
            "ê³ ì£¼íŒŒí´ë¦¬ì—í‹¸ë Œì ˆì—°ë™ì¶•ì¼€ì´ë¸”(ECX)",
            "ì¸í„°í°ì„ ã†ì „í™”ì„ ã†ì í¼ì„ (TIVã†TOVã†TJV)",
            "ìœ„ì„±ë°©ì†¡ìˆ˜ì‹ ìš©ì¼€ì´ë¸”(HFBT)",
            "ì‹ í˜¸ìš©ì¼€ì´ë¸”",
            "LAN(UTP)ì¼€ì´ë¸”(1)",
            "LAN(UTP)ì¼€ì´ë¸”(2)"
        ],
        "ê¸°íƒ€íŠ¹ìˆ˜ì¼€ì´ë¸”": [
            "ê°€ìš”ì„±ì•Œë£¨ë¯¸ëŠ„í”¼ì¼€ì´ë¸”",
            "ì „ì„ Â·ì¼€ì´ë¸”",
            "ìˆ˜ì¤‘ì¼€ì´ë¸”(CVF)",
            "ì•Œë£¨ë¯¸ëŠ„ë„ì²´ì¼€ì´ë¸”(ACSR)",
            "ì—˜ë¦¬ë² ì´í„°ì¼€ì´ë¸”",
            "í…Œí”„ë¡ ì „ì„ ",
            "ì „ê¸°ìš©ë‚˜ë™ì„ ",
            "ì—ë‚˜ë©œë™ì„ ã†ë™ë¶€ìŠ¤ë°”",
            "ëˆ„ìˆ˜/ëˆ„ìœ ê°ì§€ì‹œìŠ¤í…œ",
            "íˆíŒ…ì¼€ì´ë¸”(1)",
            "íˆíŒ…ì¼€ì´ë¸”(2)",
            "íˆíŒ…ì¼€ì´ë¸”(3)",
        ],
        "ì „ì„ ì›ë¶€ìì¬": [
            "ë¶€ìŠ¤ë•íŠ¸ ë° ë¶€í’ˆ(1)",
            "ë¶€ìŠ¤ë•íŠ¸ ë° ë¶€í’ˆ(2)",
            "ë¶€ìŠ¤ë•íŠ¸ ë° ë¶€í’ˆ(3)",
            "ë¶€ìŠ¤ë•íŠ¸ ë° ë¶€í’ˆ(4)",
            "ìŠ¬ë¦¬ë¸Œ-1",
            "ìŠ¬ë¦¬ë¸Œ-2",
            "ì¼€ì´ë¸”ì ‘ì†ì¬ ë° ì ‘ì†ìì¬",
            "ì••ì°©ë‹¨ì, ë™ê´€ë‹¨ì, EYECAP",
            "ë‹¨ìëŒ€",
            "BIMETAL LUG"
        ],
        "ì „ì„ ê´€": [
            "ê´‘ì¼€ì´ë¸”í†µì‹ ê´€",
            "ë‚˜ì‚¬ì—†ëŠ”ì „ì„ ê´€",
            "ë‚˜ì‚¬ì—†ëŠ”ì „ì„ ê´€ ë° ë¶€ì†í’ˆ(1)",
            "ë‚˜ì‚¬ì—†ëŠ”ì „ì„ ê´€ ë° ë¶€ì†í’ˆ(2)",
            "ë‚˜ì‚¬ì—†ëŠ”ì „ì„ ê´€ìš© ì›í„°ì¹˜ì´ìŒì‡ (EZì»¤ë„¥í„°)",
            "ê°•ì œì „ì„ ê´€",
            "FCí†µì‹ ê´€",
            "ê°•ì œì „ì„ ê´€ë¶€í’ˆ-1",
            "ê°•ì œì „ì„ ê´€ë¶€í’ˆ-2",
            "ë…¸ì¶œë°°ê´€ìš©ë¶€í’ˆ(ì „ì„ ê´€ìš©)",
            "ê²½ì§ˆë¹„ë‹(PVC)ì „ì„ ê´€",
            "ê²½ì§ˆë¹„ë‹(PVC)ì „ì„ ê´€ë¶€í’ˆ",
            "í•©ì„±ìˆ˜ì§€ì œê°€ìš”ì „ì„ ê´€",
            "í•©ì„±ìˆ˜ì§€ì œê°€ìš”ì „ì„ ê´€ë¶€í’ˆ",
            "íŒŒìƒí˜•ê²½ì§ˆ(ELP)ì „ì„ ê´€",
            "í´ë¦¬ì—í‹¸ë Œ(PE)ì „ì„ ê´€",
            "í›„ë ‰ì‹œë¸”ì „ì„ ê´€",
            "í›„ë ‰ì‹œë¸”ì „ì„ ê´€ë¶€í’ˆ(1)",
            "í›„ë ‰ì‹œë¸”ì „ì„ ê´€ë¶€í’ˆ(2)",
            "ëª°ë“œ",
            "ì „ì„ ë•íŠ¸"
        ],
        "ì „ì„ ê´€ë¡œì¬": [
            "ë ˆì´ìŠ¤ì›¨ì´",
            "ì¼€ì´ë¸”íƒ€ì´",
            "ì¼€ì´ë¸”ì—°ì†Œë°©ì§€ì œ ë°©í™”ì»¤ë²„",
            "íŠ¸ë ˆì´ê´€í†µë¶€ FireZero Tray ë°©í™”ì»¤ë²„",
            "ê¸ˆì†ì œë°•ìŠ¤ ë° ì»¤ë²„(ì „ì„ ê´€ìš©)",
            "í’€ë°•ìŠ¤",
            "í”Œë¼ìŠ¤í‹±ì½˜íŠ¸ë¡¤BOX(1)",
            "í”Œë¼ìŠ¤í‹±ì½˜íŠ¸ë¡¤BOX(2)",
            "í”Œë¼ìŠ¤í‹±ì½˜íŠ¸ë¡¤BOX(3)",
            "ì¼€ì´ë¸”íŠ¸ë ˆì´(KSC8464) ë° ë¶€ì†í’ˆ(1)",
            "ì¼€ì´ë¸”íŠ¸ë ˆì´(KSC8464) ë° ë¶€ì†í’ˆ(2)-1",
            "ì¼€ì´ë¸”íŠ¸ë ˆì´(KSC8464) ë° ë¶€ì†í’ˆ(2)-2",
            "CABLE TRAY (ì‚¬ë‹¤ë¦¬í˜•, LADDER TRAY)",
            "ë‚´ì§„ì„œí¬íŠ¸í–‰ê±°Â·ë‚´ì§„ì—°ê²°ì¡°ì¸íŠ¸",
            "ê´‘ë•íŠ¸",
            "ë˜ë”íŠ¸ë ˆì´",
            "í•˜ì´ë°•ìŠ¤"
        ],
        "ì „ë ¥ê¸°ê¸°": [
            "ì „ê¸°ì°¨ì¶©ì „ì†Œ ì•ˆì „ì‹œì„¤ë¬¼",
            "ì €ì†ì‹¤í•˜ì´ë¸Œë¦¬ë“œë³€ì••ê¸°",
            "ì •ë¥˜ê¸°ì¶©ì „ê¸°",
            "ë³€ì••ê¸°(1)",
            "ë³€ì••ê¸°(2)",
            "ë³€ì••ê¸°(3)",
            "ë³€ì••ê¸°(4)",
            "ë¬´ì •ì „ì „ì›ì¥ì¹˜",
            "ìë™ì „ì••ì¡°ì •ê¸°",
            "íšŒì „ìœ„ìƒë³€í™˜ê¸°",
            "ì†Œí”„íŠ¸ìŠ¤íƒ€í„°",
            "ì „í•´ìš©ì½˜ë´ì„œ(1)",
            "ì „í•´ìš©ì½˜ë´ì„œ(2)",
            "ê¸°ê¸°ìš©ì½˜ë´ì„œ",
            "ì¸ë²„í„°íŒë„¬/ì—ë„ˆì§€ì ˆì „ê¸°",
            "ì§„ìƒìš©ì½˜ë´ì„œ",
            "TWTX ì „ë™ê¸°",
            "ìœ ë„ì „ë™ê¸°",
            "ì¸ë²„í„°íŒë„¬",
            "ë§ˆì´í¬ë¡œì„œì§€í•„í„°",
            "ì¡°ì‘íŠ¸ëœìŠ¤í¬ë¨¸",
            "ì¸ë²„í„°(1)",
            "ì¸ë²„í„°(2)",
            "ì¸ë²„í„°(3)",
            "ì¸ë²„í„°(4)",
            "ì—ë„ˆì§€íšŒìƒì¥ì¹˜",
            "ì§ë¥˜ì „ë™ê¸°ì œì–´ì»¨ë²„í„°",
            "ì§ë¥˜ì „ë™ê¸°ì œì–´ë°˜"
        ],
        "ë°°ì „ê¸°ê¸°": [
            "ë³€ë¥˜ê¸°ë³´í˜¸ì¥ì¹˜",
            "í”¼ë¢°ê¸°(LA)",
            "ì•„í¬ì°¨ë‹¨ê¸°",
            "ëˆ„ì „ì°¨ë‹¨ê¸°(ELB)(1)-1",
            "ëˆ„ì „ì°¨ë‹¨ê¸°(ELB)(1)-2",
            "ëˆ„ì „ì°¨ë‹¨ê¸°(ELB)(2)",
            "ë°°ì„ ìš©ì°¨ë‹¨ê¸°(1)",
            "ë°°ì„ ìš©ì°¨ë‹¨ê¸°(2)",
            "ë°°ì„ ìš©ì°¨ë‹¨ê¸°(3)",
            "ê³ ì••ì „ë™ê¸° ì›ê²© ì ˆì—°ì €í•­ ì¸¡ì • ì‹œìŠ¤í…œ",
            "ë°°ì„ ìš©ì°¨ë‹¨ê¸°(MCCB)í•¨",
            "ê¸°ì¤‘ì°¨ë‹¨ê¸°(DC)",
            "ê¸°ì¤‘ì°¨ë‹¨ê¸°(A.C.B)",
            "ê³ ì••ê°œíê¸°",
            "ì „ìê°œíê¸°",
            "ë¬´ì •ì „ì ˆì²´ìŠ¤ìœ„ì¹˜",
            "ì§„ê³µì°¨ë‹¨ê¸°(V.C.B)",
            "íšŒë¡œã†ê°€ì¡°ì •í˜•ì°¨ë‹¨ê¸°",
            "ì „ìì ‘ì´‰ê¸°",
            "ì§„ê³µì ‘ì´‰ê¸°(VCS)",
            "ì—´ë™í˜•ê³¼ë¶€í•˜ê³„ì „ê¸°",
            "ë¸”ë¡í˜•ì „ì›ë¶„ë°°ê¸°"
        ],
        "ì ˆì—°ì¬ë£Œ": [
            "ì ˆì—°ì¬ë£Œ"
        ],
        "ìˆ˜ã†ë°°ì „ë°˜": [
            "ë¶„ì „ë°˜KIT",
            "ë¶„ì „ë°˜ Â· ê³„ëŸ‰ê¸°í•¨",
            "IoTìŠ¤ë§ˆíŠ¸ì»¨ë²„í„°",
            "ì§€ëŠ¥í˜•ë¶„ì „ë°˜",
            "ì†Œìˆ˜ë ¥ë°œì „ì¥ì¹˜"
        ],
        "ë°°ì „ì œì–´ê¸°ê¸°": [
            "ë°°ì „ì œì–´ë¶€í’ˆ",
            "ê³„ì „ê¸°(ë¦´ë ˆì´)(1)",
            "ê³„ì „ê¸°(ë¦´ë ˆì´)(2)",
            "ê³„ì „ê¸°(ë¦´ë ˆì´)(3)",
            "ê³„ì „ê¸°(ë¦´ë ˆì´)(4)",
            "ì‚°ì—…ìš©ìë™ì œì–´ê¸°ê¸°ë¶€í’ˆ"
        ],
        "ìë™í™”ê¸°ê¸°": [
            "ì›ê²©í†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ",
            "ì›ê²©ê°ì‹œì‹œìŠ¤í…œ(1)",
            "ì›ê²©ê°ì‹œì‹œìŠ¤í…œ(2)",
            "ì›ê²©ê°ì‹œì‹œìŠ¤í…œ(3)",
            "í”„ë¡œê·¸ë˜ë¨¸ë¸” ë¡œì§ ì½˜íŠ¸ë¡¤ëŸ¬(1)",
            "í”„ë¡œê·¸ë˜ë¨¸ë¸” ë¡œì§ ì½˜íŠ¸ë¡¤ëŸ¬(2)",
            "í”„ë¡œê·¸ë˜ë¨¸ë¸” ë¡œì§ ì½˜íŠ¸ë¡¤ëŸ¬(3)",
            "í”„ë¡œê·¸ë˜ë¨¸ë¸” ë¡œì§ ì½˜íŠ¸ë¡¤ëŸ¬(4)",
            "ì „ë ¥ì„ í†µì‹ ê¸°ë°˜í†µí•©ì œì–´ì‹œìŠ¤í…œ",
            "ì›ë°©ê°ì‹œì œì–´ì‹œìŠ¤í…œ(1)",
            "ì›ë°©ê°ì‹œì œì–´ì‹œìŠ¤í…œ(2)",
            "ëˆ„ìˆ˜Â·ëˆ„ì•¡Â·ëˆ„ìœ ê°ì§€ì‹œìŠ¤í…œ",
            "ìŠ¤ë§ˆíŠ¸ì„¼ì„œÂ·ì•„ì´ì†”ë ˆì´í„°"
        ],
        "ì „ë“±": [
            "í˜•ê´‘ë“±",
            "í•­ê³µë“±í™”(ë¹„í–‰ì¥ì¡°ëª…ê¸°êµ¬)(1)",
            "í•­ê³µë“±í™”(2)",
            "LEDì „êµ¬",
            "LED í˜•ê´‘ë“±",
            "LED íˆ¬ê´‘ë“±",
            "ë‚˜íŠ¸ë¥¨ë“±",
            "ë©”íƒˆí•˜ë¼ì´ë“œë“±",
            "ì¬ì‹¤ê°ì§€ì„¼ì„œ-1",
            "ì¬ì‹¤ê°ì§€ì„¼ì„œ-2"
        ],
    },

    "ì„ìœ í™”í•™": {
        "ìœ í™”ì œí’ˆ": [
            "ì„ìœ í™”í•™ì œí’ˆ"
        ],
        "í™”ê³µì•½í’ˆ": [
            "í™”ê³µì•½í’ˆ",
            "ì‹œì•½",
            "ì—ì–´ì¡¸(1)",
            "ì—ì–´ì¡¸(2)",
            "í™œì„±íƒ„ì†Œ"
        ],
        "í•©ì„±ìˆ˜ì§€Â·ê³ ë¬´ì œí’ˆ": [
            "PVCí˜¸ìŠ¤(1)",
            "PVCí˜¸ìŠ¤(2)",
            "ë¶ˆí¬í™”í´ë¦¬ì—ìŠ¤í„°ìˆ˜ì§€",
            "ë°©ì§„ã†ë°©ìŒíŒ¨ë“œ",
            "ê³ ë¬´í˜¸ìŠ¤",
            "ê³ ì••í˜¸ìŠ¤",
            "ê³ ë¬´íŒ(1)",
            "ê³ ë¬´íŒ(2)",
            "ê³ ë¬´ìš©ì•½í’ˆ",
            "Flake Lining ì¬",
            "PTFE(í…Œí”„ë¡ )íŒ",
            "POM(ì•„ì„¸íƒˆ)íŒ",
            "MC(ë‚˜ì¼ë¡ )íŒ",
            "ABSíŒ",
            "PETíŒ",
            "í¬ë§¥ìŠ¤íŒ",
            "PVCí‰íŒ",
            "PPã†PEí‰íŒ",
            "PVCã†PPã†PEë´‰",
            "ABSë´‰",
            "PTFE(í…Œí”„ë¡ )ë´‰",
            "ì—í­ì‹œë´‰",
            "ì•„í¬ë¦´ë´‰",
            "ì•„í¬ë¦´ê±°ìš¸",
            "ì•„í¬ë¦´í‰íŒ",
            "ì••ì¶œì•„í¬ë¦´íŒ",
            "ì•„í¬ë¦´íŒŒì´í”„"
        ],
        "ì—°ë£Œ": [
            "ì—°íƒ„",
            "ë¬´ì—°íƒ„",
            "ì—°ë£Œìœ ",
            "ì—°ë£Œê°€ìŠ¤",
            "ê°€ìŠ¤"
        ],
        "ê°€ìŠ¤ê¸°ê¸°": [
            "ê°€ìŠ¤ê¸°ê¸°(1)",
            "ê°€ìŠ¤ê¸°ê¸°(2)",
            "ê°€ìŠ¤ê¸°ê¸°(3)",
            "ê°€ìŠ¤ìš©ê¸°"
        ],
        "ìœ¤í™œìœ ": [
            "ì›Œì…”ì•¡",
            "ì ˆì—°ìœ ",
            "ë¶€ë™ì•¡",
            "ê·¸ë¦¬ìŠ¤(1)",
            "ê·¸ë¦¬ìŠ¤(2)",
            "ìë™ì°¨ìš©ìœ¤í™œìœ ",
            "ì‚°ì—…ìš©ìœ¤í™œìœ "
        ]
    },

    "ê¸‰ë°°ìˆ˜": {
        # ê¸‰ë°°ìˆ˜ ëŒ€ë¶„ë¥˜ì˜ ëª¨ë“  ì¤‘ë¶„ë¥˜ë¥¼ í¬í•¨
        "ë°°ê´€ì¬(â… )": "__ALL__",
        "ë°°ê´€ì¬(â…¡)": "__ALL__",
        "íŒ¨í‚¹ë¥˜": "__ALL__",
        "ë°¸ë¸Œ": "__ALL__",
        "ë¯¸í„°ã†ì—°ê²°êµ¬": "__ALL__",
        "íŒí”„ë¥˜": "__ALL__",
        "ìœ„ìƒê¸°ì¬": "__ALL__",
        "ì£¼ë°©ê¸°êµ¬": "__ALL__",
        "ì¡°ã†íƒ±í¬ë¥˜": "__ALL__",
        "íŒŒì´í”„ì»¤ë²„": "__ALL__"
    }
    }

    def __init__(self, target_major: str, start_year: str, start_month: str, max_concurrent=3):
        self.base_url = "https://www.kpi.or.kr"
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.supabase = supabase  # ì „ì—­ supabase ê°ì²´ ì°¸ì¡°
        
        # ìƒˆë¡œ ì¶”ê°€ëœ ì†ì„±ë“¤
        self.target_major_category = target_major
        self.start_year = start_year
        self.start_month = start_month
        
        self.processor = create_data_processor('kpi')
        
        # ë°°ì¹˜ ì²˜ë¦¬ìš© ë³€ìˆ˜
        self.batch_data = []
        self.batch_size = 5  # ì†Œë¶„ë¥˜ 5ê°œë§ˆë‹¤ ì²˜ë¦¬
        self.processed_count = 0
        log(f"í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”: íƒ€ê²Ÿ='{self.target_major_category}', ì‹œì‘ë‚ ì§œ={self.start_year}-{self.start_month}")

    async def run(self):
        """í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        browser = None
        try:
            async with async_playwright() as p:
                # headless=Falseë¥¼ Trueë¡œ ë³€ê²½í•˜ì—¬ ì„œë²„ í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.
                browser = await p.chromium.launch(headless=True) # â—€â—€â—€ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”!
                self.context = await browser.new_context()
                self.page = await self.context.new_page()

                await self._login()
                await self._navigate_to_category()
                await self._crawl_categories()
                
                # ë§ˆì§€ë§‰ ë‚¨ì€ ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬
                await self._process_final_batch()
                
                log(f"\nğŸŸ¢ === í¬ë¡¤ë§ ì™„ë£Œ: ì´ {self.processed_count}ê°œ ì†Œë¶„ë¥˜ ì²˜ë¦¬ë¨ === ğŸŸ¢\n")

                await browser.close()
                return self.processor
        except Exception as e:
            log(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "ERROR")
            if browser:
                try:
                    await browser.close()
                except:
                    pass
            raise

    async def _login(self):
        """ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ë¡œê·¸ì¸ ìˆ˜í–‰"""
        await self.page.goto(f"{self.base_url}/www/member/login.asp")

        username = os.environ.get("KPI_USERNAME")
        password = os.environ.get("KPI_PASSWORD")

        if not username or not password:
            raise ValueError(".env.local íŒŒì¼ì— KPI_USERNAMEê³¼ "
                             "KPI_PASSWORDë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

        await self.page.locator("#user_id").fill(username)
        await self.page.locator("#user_pw").fill(password)
        await self.page.locator("#sendLogin").click()

        await self.page.wait_for_load_state('networkidle')
        log("ë¡œê·¸ì¸ ì™„ë£Œ", "SUCCESS")

    async def _navigate_to_category(self):
        """ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ë¡œ ì´ë™ ë° ì´ˆê¸° ì„¤ì •"""
        log("ì¢…í•©ë¬¼ê°€ì •ë³´ ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        await self.page.goto(f"{self.base_url}/www/price/category.asp")

        # íŒì—… ë‹«ê¸° (ìš°ì„  ì²˜ë¦¬)
        await self._close_popups()

        # Right Quick ë©”ë‰´ ìˆ¨ê¸°ê¸°
        try:
            close_button = self.page.locator("#right_quick .q_cl")
            if await close_button.is_visible():
                await close_button.click()
                log("Right Quick ë©”ë‰´ë¥¼ ìˆ¨ê²¼ìŠµë‹ˆë‹¤.")
        except Exception as e:
            log(f"Right Quick ë©”ë‰´ ìˆ¨ê¸°ê¸° ì‹¤íŒ¨ "
                f"(ì´ë¯¸ ìˆ¨ê²¨ì ¸ ìˆì„ ìˆ˜ ìˆìŒ): {e}")

    async def _close_popups(self):
        """í˜ì´ì§€ì˜ ëª¨ë“  íŒì—…ì„ ë‹«ëŠ” ë©”ì„œë“œ"""
        try:
            # 1. ì¼ë°˜ì ì¸ íŒì—… ë‹«ê¸° ë²„íŠ¼ë“¤ ì‹œë„
            popup_close_selectors = [
                ".pop-btn-close",  # ì¼ë°˜ì ì¸ íŒì—… ë‹«ê¸° ë²„íŠ¼
                ".btnClosepop",    # íŠ¹ì • íŒì—… ë‹«ê¸° ë²„íŠ¼
                "#popupNotice .pop-btn-close",  # ê³µì§€ì‚¬í•­ íŒì—… ë‹«ê¸°
                ".ui-popup .pop-btn-close",     # UI íŒì—… ë‹«ê¸°
                "button[class*='close']",       # closeê°€ í¬í•¨ëœ ë²„íŠ¼
                "a[class*='close']"             # closeê°€ í¬í•¨ëœ ë§í¬
            ]
            
            for selector in popup_close_selectors:
                try:
                    popup_close = self.page.locator(selector)
                    if await popup_close.count() > 0:
                        # ëª¨ë“  ë§¤ì¹­ë˜ëŠ” ìš”ì†Œì— ëŒ€í•´ ë‹«ê¸° ì‹œë„
                        for i in range(await popup_close.count()):
                            element = popup_close.nth(i)
                            if await element.is_visible():
                                await element.click(timeout=3000)
                                log(f"íŒì—… ë‹«ê¸° ì„±ê³µ: {selector}")
                                await self.page.wait_for_timeout(500)  # íŒì—…ì´ ë‹«í ì‹œê°„ ëŒ€ê¸°
                except Exception:
                    continue  # ë‹¤ìŒ ì…€ë ‰í„° ì‹œë„
            
            # 2. ESC í‚¤ë¡œ íŒì—… ë‹«ê¸° ì‹œë„
            await self.page.keyboard.press('Escape')
            await self.page.wait_for_timeout(500)
            
            log("íŒì—… ë‹«ê¸° ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            log(f"íŒì—… ë‹«ê¸° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _crawl_categories(self):
        """ëŒ€ë¶„ë¥˜ -> ì¤‘ë¶„ë¥˜ -> ì†Œë¶„ë¥˜ ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§"""
        major_selector = '#left_menu_kpi > ul.panel'
        major_categories = await self.page.locator(
            major_selector).first.locator('li.file-item > a').all()

        major_links = []
        for cat in major_categories:
            text = await cat.inner_text()
            href = await cat.get_attribute('href')
            major_links.append({'name': text, 'url': f"{self.base_url}{href}"})

        for major in major_links:
            # <<< ì—¬ê¸°ì— ì½”ë“œ ì¶”ê°€ (3/4) - ëŒ€ë¶„ë¥˜ í•„í„°ë§ >>>
            if major['name'] != self.target_major_category:
                continue  # íƒ€ê²Ÿ ëŒ€ë¶„ë¥˜ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°

            log(f"ëŒ€ë¶„ë¥˜ '{major['name']}' í¬ë¡¤ë§ ì‹œì‘...")
            await self.page.goto(major['url'])
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° - ì¹´í…Œê³ ë¦¬ ëª©ë¡ì´ í‘œì‹œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            try:
                # ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì»¨í…Œì´ë„ˆ ëŒ€ê¸° (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
                selectors_to_try = [
                    ".part-list",  # ê¸°ì¡´ ì„ íƒì
                    "ul li a[href*='CATE_CD=']",  # ì¹´í…Œê³ ë¦¬ ë§í¬ë“¤
                    "li a[href*='/www/price/category.asp']",  # ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ë§í¬ë“¤
                    ".category-list",  # ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ í´ë˜ìŠ¤
                ]
                
                page_loaded = False
                for selector in selectors_to_try:
                    try:
                        await self.page.wait_for_selector(selector, timeout=10000)
                        log(f"í˜ì´ì§€ ë¡œë”© ì™„ë£Œ - ì„ íƒì: {selector}")
                        page_loaded = True
                        break
                    except Exception as e:
                        log(f"ì„ íƒì {selector} ëŒ€ê¸° ì‹¤íŒ¨: {str(e)}")
                        continue
                
                if not page_loaded:
                    log("ëª¨ë“  ì„ íƒì ì‹œë„ ì‹¤íŒ¨, ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ ì ìš©")
                    await self.page.wait_for_timeout(3000)
                    
            except Exception as e:
                log(f"í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                await self.page.wait_for_timeout(3000)

            # openSub() ë²„íŠ¼ í´ë¦­í•˜ì—¬ ëª¨ë“  ì¤‘ë¶„ë¥˜ì™€ ì†Œë¶„ë¥˜ë¥¼ í•œë²ˆì— í¼ì¹˜ê¸°
            open_sub_selector = 'a[href="javascript:openSub();"]'
            open_sub_button = self.page.locator(open_sub_selector)
            if await open_sub_button.count() > 0:
                log("openSub() ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëª¨ë“  ë¶„ë¥˜ë¥¼ í¼ì¹©ë‹ˆë‹¤.")
                await open_sub_button.click()
                # ë¶„ë¥˜ê°€ í¼ì³ì§ˆ ì‹œê°„ì„ ê¸°ë‹¤ë¦¼
                await self.page.wait_for_timeout(2000)

                # HTML êµ¬ì¡° í™•ì¸ì„ ìœ„í•´ í˜ì´ì§€ ë‚´ìš© ì¶œë ¥
                html_content = await self.page.content()
                # HTML êµ¬ì¡° í™•ì¸ì„ ìœ„í•´ í˜ì´ì§€ ë‚´ìš© ì¶œë ¥
                part_ttl_start = html_content.find('part-ttl')
                if 'part-ttl' in html_content:
                    sample_end = part_ttl_start + 1000
                    html_sample = html_content[part_ttl_start:sample_end]
                    log(f"í˜ì´ì§€ HTML ìƒ˜í”Œ (part-ttl ê´€ë ¨): {html_sample}")
                else:
                    log("í˜ì´ì§€ HTML ìƒ˜í”Œ (part-ttl ê´€ë ¨): "
                        "part-ttl ì—†ìŒ")
            else:
                # ëŒ€ë¶„ë¥˜ 'ê³µí†µìì¬' í´ë¦­í•˜ì—¬ ì¤‘ë¶„ë¥˜ ëª©ë¡ í¼ì¹˜ê¸°
                category_link = 'a[href="category.asp?CATE_CD=101"]'
                await self.page.click(category_link)
                await self.page.wait_for_timeout(1000)
                log("ì¤‘ë¶„ë¥˜ ë° ì†Œë¶„ë¥˜ ëª©ë¡ì„ í¼ì³¤ìŠµë‹ˆë‹¤.")

            # ì†Œë¶„ë¥˜ ëª©ë¡ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            await self.page.wait_for_selector(".part-list")

            # ì¤‘ë¶„ë¥˜ ì •ë³´ë¥¼ ë¯¸ë¦¬ ìˆ˜ì§‘
            middle_selector = '.part-ttl > a'
            middle_categories_elements = await self.page.locator(
                middle_selector).all()
            log(f"  ë°œê²¬ëœ ì¤‘ë¶„ë¥˜ ê°œìˆ˜: {len(middle_categories_elements)}")

            middle_categories_info = []
            for i, middle_element in enumerate(middle_categories_elements):
                try:
                    middle_name = await middle_element.inner_text()
                    middle_href = await middle_element.get_attribute('href')
                    if middle_href and 'CATE_CD=' in middle_href:
                        middle_categories_info.append({
                            'name': middle_name,
                            'href': middle_href
                        })
                        log(f"  ë°œê²¬ëœ ì¤‘ë¶„ë¥˜: '{middle_name}' "
                            f"(CATE_CD: {middle_href})")
                except Exception as e:
                    log(f"  ì¤‘ë¶„ë¥˜ {i + 1} ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue

            # ê° ì¤‘ë¶„ë¥˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë°©ë¬¸í•˜ì—¬ ì†Œë¶„ë¥˜ ìˆ˜ì§‘
            for middle_info in middle_categories_info:
                middle_name = middle_info['name']
                middle_href = middle_info['href']
                # <<< ì¤‘ë¶„ë¥˜ í¬í•¨ ë¡œì§ >>>
                inclusions_for_major = self.INCLUSION_LIST.get(major['name'], {})
                
                # ëŒ€ë¶„ë¥˜ì— ì„¤ì •ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì¤‘ë¶„ë¥˜ ì œì™¸
                if not inclusions_for_major:
                    log(f"  [SKIP] í¬í•¨ ëª©ë¡ ì—†ìŒ: ì¤‘ë¶„ë¥˜ '{middle_name}' ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                # ëŒ€ë¶„ë¥˜ê°€ "__ALL__"ë¡œ ì„¤ì •ëœ ê²½ìš° ëª¨ë“  ì¤‘ë¶„ë¥˜ í¬í•¨
                if inclusions_for_major == "__ALL__":
                    log(f"  ì¤‘ë¶„ë¥˜ '{middle_name}' í¬í•¨ (ëŒ€ë¶„ë¥˜ ì „ì²´ í¬í•¨ ì„¤ì •)")
                else:
                    # ì¤‘ë¶„ë¥˜ê°€ í¬í•¨ ëª©ë¡ì— ì—†ìœ¼ë©´ ì œì™¸
                    if middle_name not in inclusions_for_major:
                        log(f"  [SKIP] í¬í•¨ ëª©ë¡ì— ì—†ìŒ: ì¤‘ë¶„ë¥˜ '{middle_name}' ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue

                try:
                    # ì¤‘ë¶„ë¥˜ í˜ì´ì§€ë¡œ ì´ë™
                    middle_url = f"{self.base_url}/www/price/{middle_href}"
                    log(f"  ì¤‘ë¶„ë¥˜ '{middle_name}' "
                        f"í˜ì´ì§€ë¡œ ì´ë™: {middle_url}")
                    await self.page.goto(middle_url)
                    await self.page.wait_for_load_state(
                        'networkidle')

                    # ì†Œë¶„ë¥˜ê°€ ìˆ¨ê²¨ì ¸ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì§ì ‘ ì°¾ê¸°
                    await self.page.wait_for_timeout(2000)

                    # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì†Œë¶„ë¥˜ ì°¾ê¸°
                    sub_categories_info = []

                    # ë°©ë²• 1: ul.part-list ë‚´ì˜ ë§í¬ë“¤
                    part_list_selector = 'ul.part-list'
                    part_lists = await self.page.locator(
                        part_list_selector).all()
                    for part_list in part_lists:
                        if await part_list.count() > 0:
                            sub_selector = 'li a'
                            sub_elements = await part_list.locator(
                                sub_selector).all()
                            for sub_element in sub_elements:
                                try:
                                    sub_name = await sub_element.inner_text()
                                    sub_href = await sub_element.get_attribute(
                                        'href')
                                    has_cate_cd = (
                                        sub_href and
                                        'CATE_CD=' in sub_href)
                                    if has_cate_cd:
                                        sub_categories_info.append({
                                            'name': sub_name,
                                            'href': sub_href
                                        })
                                        log(f"    ë°œê²¬ëœ ì†Œë¶„ë¥˜: "
                                            f"'{sub_name}'")
                                except Exception as e:
                                    log(f"    ì†Œë¶„ë¥˜ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: "
                                        f"{str(e)}")
                                    continue

                    # ë°©ë²• 2: ë§Œì•½ ìœ„ì—ì„œ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ë‹¤ë¥¸ ì„ íƒì ì‹œë„
                    if not sub_categories_info:
                        try:
                            # ì†Œë¶„ë¥˜ ë§í¬ ì°¾ê¸°
                            detail_selector = (
                                'a[href*="detail.asp?CATE_CD="]')
                            all_links = await self.page.locator(
                                detail_selector).all()
                            for link in all_links:
                                try:
                                    sub_name = await link.inner_text()
                                    sub_href = await link.get_attribute(
                                        'href')
                                    if sub_href and sub_name.strip():
                                        sub_categories_info.append({
                                            'name': sub_name.strip(),
                                            'href': sub_href
                                        })
                                except Exception:
                                    continue
                        except Exception as e:
                            # ë°©ë²•2 ì†Œë¶„ë¥˜ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¡œê·¸ ìƒëµ)
                            pass

                    if not sub_categories_info:
                        log(f"    ì¤‘ë¶„ë¥˜ '{middle_name}'ì˜ "
                            f"ì†Œë¶„ë¥˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    sub_count = len(sub_categories_info)
                    log(f"    ì¤‘ë¶„ë¥˜ '{middle_name}' - "
                        f"ë°œê²¬ëœ ì†Œë¶„ë¥˜ ê°œìˆ˜: {sub_count}")

                    # ìˆ˜ì§‘ëœ ì†Œë¶„ë¥˜ ì •ë³´ë¡œ ë³‘ë ¬ ë°ì´í„° í¬ë¡¤ë§
                    await self._crawl_subcategories_parallel(
                        major['name'], middle_name, sub_categories_info)

                except Exception as e:
                    log(f"  ì¤‘ë¶„ë¥˜ '{middle_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue

    async def _crawl_subcategories_parallel(self, major_name,
                                            middle_name,
                                            sub_categories_info):
        """ì†Œë¶„ë¥˜ë“¤ì„ ë³‘ë ¬ë¡œ í¬ë¡¤ë§"""
        # <<< ì†Œë¶„ë¥˜ í¬í•¨ ë¡œì§ >>>
        inclusions_for_major = self.INCLUSION_LIST.get(major_name, {})
        
        # ëŒ€ë¶„ë¥˜ê°€ "__ALL__"ë¡œ ì„¤ì •ëœ ê²½ìš° ëª¨ë“  ì¤‘ë¶„ë¥˜ì™€ ì†Œë¶„ë¥˜ í¬í•¨
        if inclusions_for_major == "__ALL__":
            log(f"    ëŒ€ë¶„ë¥˜ '{major_name}' ì „ì²´ í¬í•¨ ì„¤ì • - ì¤‘ë¶„ë¥˜ '{middle_name}' ëª¨ë“  ì†Œë¶„ë¥˜ í¬í•¨")
        else:
            sub_inclusion_rule = inclusions_for_major.get(middle_name, [])
            
            # ì¤‘ë¶„ë¥˜ê°€ "__ALL__"ì´ ì•„ë‹Œ ê²½ìš°, íŠ¹ì • ì†Œë¶„ë¥˜ë§Œ í¬í•¨
            if sub_inclusion_rule != "__ALL__":
                if isinstance(sub_inclusion_rule, list) and sub_inclusion_rule:
                    filtered_subs = []
                    for sub_info in sub_categories_info:
                        if sub_info['name'] in sub_inclusion_rule:
                            filtered_subs.append(sub_info)
                        else:
                            log(f"    [SKIP] í¬í•¨ ëª©ë¡ì— ì—†ìŒ: ì†Œë¶„ë¥˜ '{sub_info['name']}' ê±´ë„ˆëœë‹ˆë‹¤.")
                    sub_categories_info = filtered_subs  # í•„í„°ë§ëœ ëª©ë¡ìœ¼ë¡œ êµì²´
                else:
                    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ê±°ë‚˜ ì˜ëª»ëœ í˜•ì‹ì¸ ê²½ìš° ëª¨ë“  ì†Œë¶„ë¥˜ ì œì™¸
                    log(f"    [SKIP] í¬í•¨í•  ì†Œë¶„ë¥˜ ì—†ìŒ: ì¤‘ë¶„ë¥˜ '{middle_name}' ëª¨ë“  ì†Œë¶„ë¥˜ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return

        if not sub_categories_info:
            log(f"    ì¤‘ë¶„ë¥˜ '{middle_name}': "
                f"ì²˜ë¦¬í•  ì†Œë¶„ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        sub_count = len(sub_categories_info)
        log(f"    ì¤‘ë¶„ë¥˜ '{middle_name}': {sub_count}ê°œ "
            f"ì†Œë¶„ë¥˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

        # ë³‘ë ¬ ì‘ì—… ìƒì„±
        tasks = []
        for sub_info in sub_categories_info:
            task = self._crawl_single_subcategory(
                major_name, middle_name, sub_info)
            tasks.append(task)

        # ë³‘ë ¬ ì‹¤í–‰
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ì²˜ë¦¬ ë° ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘
        success_count = 0
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                sub_name = sub_categories_info[i]['name']
                log(f"    ì†Œë¶„ë¥˜ '{sub_name}' ì²˜ë¦¬ ì‹¤íŒ¨: {str(result)}")
            else:
                success_count += 1
                # ì„±ê³µí•œ ì†Œë¶„ë¥˜ ë°ì´í„°ë¥¼ ë°°ì¹˜ì— ì¶”ê°€
                sub_info = sub_categories_info[i]
                self.batch_data.append({
                    'major': major_name,
                    'middle': middle_name,
                    'sub': sub_info['name'],
                    'result': result
                })
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì²˜ë¦¬
                if len(self.batch_data) >= self.batch_size:
                    await self._process_batch()

        total_count = len(sub_categories_info)
        log(f"    ì¤‘ë¶„ë¥˜ '{middle_name}' ì™„ë£Œ: "
            f"{success_count}/{total_count}ê°œ ì„±ê³µ")
    
    async def _process_batch(self):
        """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (pandas ê°€ê³µ ë° supabase ì €ì¥)"""
        if not self.batch_data:
            return
            
        batch_count = len(self.batch_data)
        log(f"\n=== ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {batch_count}ê°œ ì†Œë¶„ë¥˜ ===\n")
        
        # ê° ì†Œë¶„ë¥˜ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        total_processed = 0
        total_saved = 0
        
        for batch_item in self.batch_data:
            try:
                # pandas ê°€ê³µ
                processed_data = await self.processor.process_data(
                    batch_item['major'], 
                    batch_item['middle'], 
                    batch_item['sub']
                )
                
                if processed_data:
                    processed_count = len(processed_data)
                    total_processed += processed_count
                    
                    # supabase ì €ì¥
                    saved_count = await self.processor.save_to_supabase(processed_data)
                    total_saved += saved_count
                    
                    log(f"  - {batch_item['sub']}: pandas ê°€ê³µ {processed_count}ê°œ, "
                        f"supabase ì €ì¥ {saved_count}ê°œ")
                else:
                    log(f"  - {batch_item['sub']}: ì²˜ë¦¬í•  ë°ì´í„° ì—†ìŒ")
                    
            except Exception as e:
                log(f"  - {batch_item['sub']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        
        log(f"\n=== ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: pandas ê°€ê³µ {total_processed}ê°œ, "
            f"supabase ì €ì¥ {total_saved}ê°œ ===\n")
        
        # ë°°ì¹˜ ë°ì´í„° ì´ˆê¸°í™”
        self.batch_data = []
        self.processed_count += batch_count
    
    async def _process_final_batch(self):
        """ë§ˆì§€ë§‰ ë‚¨ì€ ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬"""
        if self.batch_data:
            log(f"\n=== ìµœì¢… ë°°ì¹˜ ì²˜ë¦¬: {len(self.batch_data)}ê°œ ì†Œë¶„ë¥˜ ===\n")
            await self._process_batch()

    async def _crawl_single_subcategory(self, major_name,
                                        middle_name, sub_info):
        """ë‹¨ì¼ ì†Œë¶„ë¥˜ í¬ë¡¤ë§ (ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ)"""
        async with self.semaphore:
            sub_name = sub_info['name']
            sub_href = sub_info['href']
            sub_url = f"{self.base_url}/www/price/{sub_href}"

            log(f"  - ì¤‘ë¶„ë¥˜ '{middle_name}' > "
                f"ì†Œë¶„ë¥˜ '{sub_name}' ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

            try:
                # ìƒˆë¡œìš´ í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´)
                new_page = await self.context.new_page()
                await new_page.goto(sub_url)
                await new_page.wait_for_load_state('networkidle')

                # ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
                result = await self._get_price_data_with_page(
                    new_page, major_name, middle_name, sub_name, sub_url)

                # í˜ì´ì§€ ì •ë¦¬
                await new_page.close()

                # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì²˜ë¦¬í•˜ê³  ì €ì¥
                has_data = (result and hasattr(result, 'raw_data_list')
                            and result.raw_data_list)
                if has_data:
                    log(f"  - ì†Œë¶„ë¥˜ '{sub_name}' ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥ ì‹œì‘")

                    # DataFrameìœ¼ë¡œ ë³€í™˜
                    df = result.to_dataframe()

                    if not df.empty:
                        # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                        processed_data = df.to_dict(orient='records')
                        # Supabaseì— ì €ì¥ (ì¤‘ë³µ ì²´í¬ í™œì„±í™”)
                        saved_count = await result.save_to_supabase(processed_data, 'kpi_price_data', check_duplicates=True)
                        log(f"  âœ… '{sub_name}' ì™„ë£Œ: "
                            f"{len(df)}ê°œ ë°ì´í„° â†’ Supabase ì €ì¥ {saved_count}ê°œ ì„±ê³µ")
                    else:
                        log(f"  âš ï¸ '{sub_name}' ì™„ë£Œ: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")

                return result

            except Exception as e:
                error_msg = (f"  ì†Œë¶„ë¥˜ '{sub_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ "
                             f"[ëŒ€ë¶„ë¥˜: {major_name}, ì¤‘ë¶„ë¥˜: {middle_name}]: "
                             f"{str(e)}")
                log(error_msg)
                raise e

    async def _get_price_data(self, major_name, middle_name,
                             sub_name, sub_url):
        """ê¸°ì¡´ ë©”ì„œë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
        return await self._get_price_data_with_page(
            self.page, major_name, middle_name, sub_name, sub_url)



    async def _check_existing_data(self, major_name, middle_name, 
                                  sub_name, spec_name):
        """Supabaseì—ì„œ ê¸°ì¡´ ë°ì´í„° í™•ì¸í•˜ì—¬ ì¤‘ë³µ ì²´í¬"""
        try:
            response = self.supabase.table('kpi_price_data').select(
                'date, region, price, specification'
            ).eq(
                'major_category', major_name
            ).eq(
                'middle_category', middle_name
            ).eq(
                'sub_category', sub_name
            ).eq(
                'specification', spec_name
            ).execute()
            
            if response.data:
                # (ë‚ ì§œ, ì§€ì—­, ê°€ê²©, ê·œê²©) ì¡°í•©ìœ¼ë¡œ ì™„ì „ ì¤‘ë³µ ì²´í¬
                # pandas ê°€ê³µ í›„ ì»¬ëŸ¼ëª… ë³€ê²½ ê³ ë ¤ (region_name -> region)
                existing_data = set()
                for item in response.data:
                    existing_data.add((item['date'], item['region'], str(item['price']), item['specification']))
                log(f"        - ê¸°ì¡´ ë°ì´í„° ë°œê²¬: {len(existing_data)}ê°œ (ë‚ ì§œ-ì§€ì—­-ê°€ê²©-ê·œê²© ì¡°í•©)")
                return existing_data
            else:
                log("        - ê¸°ì¡´ ë°ì´í„° ì—†ìŒ: ì „ì²´ ì¶”ì¶œ í•„ìš”")
                return set()
                
        except Exception as e:
            log(f"        - ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return set()  # ì˜¤ë¥˜ ì‹œ ì „ì²´ ì¶”ì¶œ
    
    async def _get_available_date_range(self, page):
        """í˜ì´ì§€ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ í™•ì¸"""
        try:
            # í—¤ë”ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            selector = "#priceTrendDataArea th"
            await page.wait_for_selector(selector, timeout=5000)
            header_elements = await page.locator(selector).all()

            if len(header_elements) > 1:
                dates = []
                for i in range(1, len(header_elements)):
                    header_text = await header_elements[i].inner_text()
                    dates.append(header_text.strip())
                return dates
            else:
                return []

        except Exception as e:
            log(f"        - ë‚ ì§œ ë²”ìœ„ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []

    async def _get_price_data_with_page(self, page, major_name, 
                                        middle_name, sub_name, sub_url):
        """ì†Œë¶„ë¥˜ í˜ì´ì§€ì—ì„œ ì›”ë³„ ê°€ê²© ë°ì´í„°ë¥¼ ì¶”ì¶œ"""
        try:
            # í˜ì´ì§€ ìƒíƒœ í™•ì¸
            if page.is_closed():
                log(f"í˜ì´ì§€ê°€ ë‹«í˜€ìˆì–´ '{sub_name}' ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.", "ERROR")
                return None
                
            # í˜ì´ì§€ëŠ” ì´ë¯¸ ë¡œë“œëœ ìƒíƒœë¡œ ì „ë‹¬ë¨
            await page.wait_for_load_state('networkidle', timeout=30000)

            # 'ë¬¼ê°€ì¶”ì´ ë³´ê¸°' íƒ­ìœ¼ë¡œ ì´ë™
            try:
                # íƒ­ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
                await page.wait_for_selector('a:has-text("ë¬¼ê°€ì¶”ì´ ë³´ê¸°")', timeout=15000)
                
                # ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
                for retry in range(3):
                    try:
                        await page.get_by_role('link', name='ë¬¼ê°€ì¶”ì´ ë³´ê¸°').click(timeout=30000)
                        await page.wait_for_selector("#ITEM_SPEC_CD", timeout=30000)
                        break
                    except Exception as e:
                        if retry == 2:
                            raise e
                        log(f"ë¬¼ê°€ì¶”ì´ ë³´ê¸° íƒ­ í´ë¦­ ì¬ì‹œë„ {retry + 1}/3: {e}", "WARNING")
                        await page.reload()
                        await page.wait_for_load_state('networkidle', timeout=30000)
                        
            except Exception as e:
                log(f"ë¬¼ê°€ì¶”ì´ ë³´ê¸° íƒ­ í´ë¦­ ì‹¤íŒ¨: {str(e)}", "ERROR")
                return None

            # ê·œê²© ì„ íƒ ì˜µì…˜ë“¤ ê°€ì ¸ì˜¤ê¸°
            spec_options = await page.locator('#ITEM_SPEC_CD option').all()

            raw_item_data = {
                'major_category_name': major_name,
                'middle_category_name': middle_name,
                'sub_category_name': sub_name,
                'spec_data': []
            }

            # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê·œê²© ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘
            spec_list = []
            for option in spec_options:
                spec_value = await option.get_attribute('value')
                spec_name = await option.inner_text()
                if spec_value and spec_name.strip():  # ë¹ˆ ê°’ ì œì™¸
                    spec_list.append({'value': spec_value, 'name': spec_name})

            # ëª¨ë“  ê·œê²©ì„ ìµœì í™”ëœ ìˆœì°¨ ì²˜ë¦¬ë¡œ ì§„í–‰
            log(f"    - {len(spec_list)}ê°œ ê·œê²©ì„ "
                f"ìµœì í™”ëœ ìˆœì°¨ ì²˜ë¦¬ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            await self._process_specs_optimized(
                page, spec_list, raw_item_data,
                major_name, middle_name, sub_name)

        except Exception as e:
            log(f"  ì†Œë¶„ë¥˜ '{sub_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ "
                f"[ëŒ€ë¶„ë¥˜: {major_name}, ì¤‘ë¶„ë¥˜: {middle_name}]: {str(e)}", "ERROR")
            return None

        # ìˆ˜ì§‘ëœ ë°ì´í„° ì²˜ë¦¬ - ìƒˆë¡œìš´ DataProcessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        local_processor = create_data_processor('kpi')
        if raw_item_data['spec_data']:
            local_processor.add_raw_data(raw_item_data)
            spec_count = len(raw_item_data['spec_data'])
            log(f"  - '{sub_name}' ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ "
                f"(ì´ {spec_count}ê°œ ê·œê²©)")
        else:
            log(f"  - '{sub_name}': ìˆ˜ì§‘ëœ ê·œê²© ë°ì´í„° ì—†ìŒ")

        return local_processor

    async def _process_specs_optimized(
            self, page, spec_list, raw_item_data,
            major_name, middle_name, sub_name):
        """ìµœì í™”ëœ ìˆœì°¨ ì²˜ë¦¬ - í˜ì´ì§€ ë¦¬ë¡œë“œ ì—†ì´ ë¹ ë¥¸ ê·œê²© ë³€ê²½"""
        for i, spec in enumerate(spec_list):
            try:
                spec_value = spec['value']
                spec_name = spec['name']
                log(f"      - ê·œê²© {i + 1}/{len(spec_list)}: "
                    f"'{spec_name}' ì¡°íšŒ ì¤‘...")

                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                existing_dates = await self._check_existing_data(
                    major_name, middle_name, sub_name, spec_name
                )

                # ê·œê²© ì„ íƒ (ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”)
                spec_selector = '#ITEM_SPEC_CD'
                await page.locator(spec_selector).select_option(
                    value=spec_value)
                await page.wait_for_load_state('networkidle', timeout=3000)

                # ê¸°ê°„ ì„ íƒ (ì²« ë²ˆì§¸ ê·œê²©ì—ì„œë§Œ ì„¤ì •)
                if i == 0:
                    # ì‹œì‘ ê¸°ê°„: 2020ë…„ 1ì›”
                    year_from_selector = '#DATA_YEAR_F'
                    month_from_selector = '#DATA_MONTH_F'
                    await page.locator(year_from_selector).select_option(
                        value='2020')
                    await page.locator(month_from_selector).select_option(
                        value='01')
                    
                    # ì¢…ë£Œ ê¸°ê°„: í˜„ì¬ ë…„ì›”
                    current_date = datetime.now()
                    current_year = str(current_date.year)
                    current_month = str(current_date.month).zfill(2)
                    
                    year_to_selector = '#DATA_YEAR_T'
                    month_to_selector = '#DATA_MONTH_T'
                    await page.locator(year_to_selector).select_option(
                        value=current_year)
                    await page.locator(month_to_selector).select_option(
                        value=current_month)
                    
                    await page.wait_for_load_state(
                        'networkidle', timeout=3000)
                    
                    # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ (ê¸°ê°„ ì„¤ì • í›„ ë°˜ë“œì‹œ ì‹¤í–‰)
                    search_selector = 'form[name="sForm"] input[type="image"]'
                    search_button = page.locator(search_selector)
                    await search_button.click(timeout=5000)
                    log(f"        - ê¸°ê°„ ì„¤ì • ì™„ë£Œ: 2020.01 ~ "
            f"{current_year}.{current_month}")
                else:
                    # ì²« ë²ˆì§¸ ê·œê²©ì´ ì•„ë‹Œ ê²½ìš°ì—ë„ ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
                    search_selector = 'form[name="sForm"] input[type="image"]'
                    search_button = page.locator(search_selector)
                    await search_button.click(timeout=5000)

                # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸° (ë°ì´í„°ê°€ ë¡œë“œë  ë•Œê¹Œì§€)
                table_selector = "#priceTrendDataArea tr"
                await page.wait_for_selector(table_selector, timeout=8000)
                await page.wait_for_load_state('networkidle', timeout=5000)

                # ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ í™•ì¸
                available_dates = await self._get_available_date_range(page)
                if not available_dates:
                    log("        - ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì—†ìŒ")
                    continue
                
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ
                existing_date_set = set()
                if existing_dates:
                    existing_date_set = {item[0] for item in existing_dates}  # íŠœí”Œì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ë‚ ì§œ)ë§Œ ì¶”ì¶œ
                
                # ëˆ„ë½ëœ ë‚ ì§œë§Œ ì¶”ì¶œ
                missing_dates = [date for date in available_dates 
                               if date not in existing_date_set]
                
                if not missing_dates:
                    continue
                
                # ëˆ„ë½ëœ ë‚ ì§œì— ëŒ€í•´ì„œë§Œ ê°€ê²© ë°ì´í„° ì¶”ì¶œ
                await self._extract_price_data_fast(
                    page, spec_name, raw_item_data, existing_dates)

            except Exception as e:
                # ê·œê²© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜
                log(f"ê·œê²© '{spec['name']}' ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", "ERROR")
                continue

    async def _extract_price_data_fast(self, page, spec_name,
                                       raw_item_data, existing_dates=None):
        """ë¹ ë¥¸ ê°€ê²© ë°ì´í„° ì¶”ì¶œ - ëˆ„ë½ëœ ë°ì´í„°ë§Œ ì¶”ì¶œ"""
        try:
            # ë¬¼ê°€ì¶”ì´ ë³´ê¸° íƒ­ì˜ í…Œì´ë¸” êµ¬ì¡° (ì‹¤ì œ í™•ì¸ëœ êµ¬ì¡°):
            # - ì²« ë²ˆì§¸ í–‰: ì§€ì—­ í—¤ë” ("êµ¬ë¶„", "ì„œâ‘ ìš¸", "ì„œâ‘¡ìš¸", "ë¶€â‘ ì‚°", ...)
            # - ë‘ ë²ˆì§¸ í–‰ë¶€í„°: ë‚ ì§œë³„ ë°ì´í„° ("2024. 9", ê°€ê²©1, ê°€ê²©2, ...)
            
            # ì§€ì—­ í—¤ë” í–‰ ì¶”ì¶œ (ì²« ë²ˆì§¸ í–‰)
            region_header_row = None
            region_header_elements = []
            
            # í…Œì´ë¸”ì—ì„œ ì²« ë²ˆì§¸ í–‰ ì°¾ê¸° (ì§€ì—­ í—¤ë”)
            all_table_rows = await page.locator("table").nth(1).locator("tr").all()  # ë‘ ë²ˆì§¸ í…Œì´ë¸” ì‚¬ìš©
            if len(all_table_rows) >= 1:
                region_header_row = all_table_rows[0]
                region_header_elements = await region_header_row.locator("td").all()
                if not region_header_elements:
                    region_header_elements = await region_header_row.locator("th").all()
                log(f"      - ì§€ì—­ í—¤ë” ë°œê²¬ (ì²« ë²ˆì§¸ í–‰): "
                    f"{len(region_header_elements)}ê°œ ì»¬ëŸ¼")
            
            if not region_header_elements:
                log(f"      - ê·œê²© '{spec_name}': ì§€ì—­ í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            # ì§€ì—­ í—¤ë” ì¶”ì¶œ (ì²« ë²ˆì§¸ ì»¬ëŸ¼ 'êµ¬ë¶„' ì œì™¸, ìœ íš¨í•œ ì§€ì—­ë§Œ)
            regions = []
            # ìœ íš¨í•œ ì§€ì—­ì˜ ì¸ë±ìŠ¤ ì €ì¥
            valid_region_indices = []
            for i in range(1, len(region_header_elements)):
                header_text = await region_header_elements[i].inner_text()
                region_name = self._clean_region_name(header_text.strip())
                if self._is_valid_region_name(region_name):
                    regions.append(region_name)
                    valid_region_indices.append(i)

            if not regions:
                return

            # ë°ì´í„° í–‰ ì¶”ì¶œ (ë‘ ë²ˆì§¸ í–‰ë¶€í„° - ë‚ ì§œë³„ ë°ì´í„°)
            data_rows = []
            if len(all_table_rows) >= 2:
                data_rows = all_table_rows[1:]  # ì²« ë²ˆì§¸ í–‰(ì§€ì—­ í—¤ë”) ì œì™¸
            
            if not data_rows:
                return

            extracted_count = 0
            # ê° ë‚ ì§œë³„ ë°ì´í„° ì²˜ë¦¬ (í–‰ì´ ë‚ ì§œ, ì—´ì´ ì§€ì—­)
            for row_idx, row in enumerate(data_rows):
                try:
                    # ì²« ë²ˆì§¸ ì…€ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                    date_element = row.locator("td").first
                    if not await date_element.count():
                        date_element = row.locator("th").first

                    if not await date_element.count():
                        continue

                    date_str = await date_element.inner_text()
                    date_clean = date_str.strip()
                    
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ ë° ì¤‘ë³µ ì²´í¬
                    if not self._is_valid_date_value(date_clean):
                        continue
                    
                    formatted_date = self._format_date_header(date_clean)
                    if not formatted_date:
                        continue
                    
                    # ì´ ë‚ ì§œì— ëŒ€í•´ ì²˜ë¦¬í•  ì§€ì—­ë“¤ì„ í™•ì¸
                    
                    # ë‚ ì§œ ìœ íš¨ì„± ì¬ê²€ì¦ (ì¶”ê°€ ê²€ì¦)
                    if not self._is_valid_date_header(date_clean):
                        continue

                    # í•´ë‹¹ í–‰ì˜ ëª¨ë“  ê°€ê²© ì…€ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì…€ ì œì™¸)
                    price_cells = await row.locator("td").all()
                    if not price_cells:
                        # tdê°€ ì—†ìœ¼ë©´ thì—ì„œ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì œì™¸)
                        all_cells = await row.locator("th").all()
                        price_cells = all_cells[1:] if len(all_cells) > 1 else []

                    # ê° ì§€ì—­ë³„ ê°€ê²© ì²˜ë¦¬ (ì—´ì´ ì§€ì—­)
                    for region_idx, region_name in enumerate(regions):
                        # ê°€ê²© ì…€ ì¸ë±ìŠ¤ëŠ” 1ë¶€í„° ì‹œì‘ (ì²« ë²ˆì§¸ ì…€ì€ ë‚ ì§œ)
                        cell_idx = region_idx + 1
                        if cell_idx >= len(price_cells):
                            continue
                            
                        price_cell = price_cells[cell_idx]
                        price_str = await price_cell.inner_text()
                        
                        if self._is_valid_price(price_str):
                            clean_price = (price_str.strip()
                                        .replace(',', ''))
                            try:
                                price_value = float(clean_price)
                                
                                # (ë‚ ì§œ, ì§€ì—­, ê°€ê²©, ê·œê²©) ì¡°í•©ìœ¼ë¡œ ì™„ì „ ì¤‘ë³µ ì²´í¬
                                if existing_dates and (formatted_date, region_name, str(price_value), spec_name) in existing_dates:
                                    continue
                                price_data = {
                                    'spec_name': spec_name,
                                    'region': region_name,
                                    'date': formatted_date,
                                    'price': price_value
                                }
                                spec_data = raw_item_data['spec_data']
                                spec_data.append(price_data)
                                extracted_count += 1
                                
                                # ë¡œê·¸ ìµœì í™”: ê°œë³„ ë°ì´í„° ë¡œê·¸ ì œê±°
                                if extracted_count % 50 == 0:  # 50ê°œë§ˆë‹¤ ì§„í–‰ìƒí™©ë§Œ í‘œì‹œ
                                    log(f"ì§„í–‰: {extracted_count}ê°œ ì¶”ì¶œë¨")
                            except ValueError as ve:
                                continue
                        else:
                            # ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨ - ë¡œê·¸ ìƒëµ
                            continue
                except Exception as e:
                    log(f"      - í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue

            if extracted_count > 0:
                log(f"'{spec_name}': {extracted_count}ê°œ ì™„ë£Œ", "SUCCESS")

        except Exception as e:
            log(f"'{spec_name}' ì˜¤ë¥˜: {str(e)}", "ERROR")

    def _clean_region_name(self, region_str):
        """ì§€ì—­ëª… ì •ë¦¬ í•¨ìˆ˜ - 'ì„œìš¸1', 'ë¶€ì‚°2' í˜•íƒœë¡œ ì •ê·œí™”"""
        import re
        
        # ë™ê·¸ë¼ë¯¸ ìˆ«ìë¥¼ ì¼ë°˜ ìˆ«ìë¡œ ë³€í™˜
        circle_to_num = {
            'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5',
            'â‘¥': '6', 'â‘¦': '7', 'â‘§': '8', 'â‘¨': '9', 'â‘©': '10'
        }
        clean_region = region_str.strip()
        for circle, num in circle_to_num.items():
            clean_region = clean_region.replace(circle, num)
        
        # 'ì„œ1ìš¸' â†’ 'ì„œìš¸1' í˜•íƒœë¡œ ë³€í™˜
        pattern = r'^([ê°€-í£])(\d+)([ê°€-í£]+)$'
        match = re.match(pattern, clean_region)
        
        if match:
            first_char, number, rest = match.groups()
            clean_region = f"{first_char}{rest}{number}"
        
        return clean_region

    def _is_valid_date_header(self, header_text):
        """ë‚ ì§œ í—¤ë” ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜"""
        if not header_text or not header_text.strip():
            return False

        header_str = header_text.strip()
        
        # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°
        if not header_str or header_str.isspace():
            return False

        # ë‚ ì§œ íŒ¨í„´ í™•ì¸ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        date_patterns = [
            r'^\d{4}\.\d{1,2}$',  # YYYY.M
            r'^\d{4}-\d{1,2}$',   # YYYY-M
            r'^\d{4}/\d{1,2}$',   # YYYY/M
            r'^\d{4}\.\s*\d{1,2}$',  # YYYY. M (ê³µë°± í¬í•¨)
            r'^\d{4}ë…„\s*\d{1,2}ì›”$',  # YYYYë…„ Mì›”
            r'^\d{4}\s+\d{1,2}$'  # YYYY M (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
        ]
        
        for pattern in date_patterns:
            if re.match(pattern, header_str):
                return True

        # ê¸°íƒ€ ì˜ëª»ëœ ê°’ ì²´í¬ (ë” í¬ê´„ì ìœ¼ë¡œ)
        invalid_patterns = [
            'êµ¬ë¶„', 'ì§€ì—­', 'í‰ê· ', 'ì „êµ­', 'ê¸°ì¤€', 'í•©ê³„', 'ì´ê³„', 'ì†Œê³„',
            'ë‹¨ìœ„', 'ì›', 'ì²œì›', 'ë§Œì›', 'ì–µì›',
            'ê·œê²©', 'í’ˆëª©', 'ìì¬', 'ì¬ë£Œ'
        ]
        
        for pattern in invalid_patterns:
            if pattern in header_str:
                log(f"        - ì˜ëª»ëœ íŒ¨í„´ìœ¼ë¡œ ì¸ì‹ëœ ë‚ ì§œ í—¤ë” ì œì™¸: {header_str}")
                return False
        
        # ìˆ«ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš° (ì—°ë„ë‚˜ ì›”ë§Œ ìˆëŠ” ê²½ìš°)
        if header_str.isdigit():
            # 4ìë¦¬ ìˆ«ìëŠ” ì—°ë„ë¡œ ì¸ì •
            if len(header_str) == 4 and 1900 <= int(header_str) <= 2100:
                return True
            # 1-2ìë¦¬ ìˆ«ìëŠ” ì›”ë¡œ ì¸ì •
            elif len(header_str) <= 2 and 1 <= int(header_str) <= 12:
                return True
            else:
                return False

        return False

    def _format_date_header(self, header_text):
        """ë‚ ì§œ í—¤ë”ë¥¼ YYYY-MM-01 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not header_text or not header_text.strip():
            return header_text
            
        header_str = header_text.strip()
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒ¨í„´ ì²˜ë¦¬
        date_patterns = [
            (r'^(\d{4})\.(\d{1,2})$', '-'),  # YYYY.M
            (r'^(\d{4})-(\d{1,2})$', '-'),   # YYYY-M
            (r'^(\d{4})/(\d{1,2})$', '-'),   # YYYY/M
            (r'^(\d{4})\.\s*(\d{1,2})$', '-'),  # YYYY. M (ê³µë°± í¬í•¨)
            (r'^(\d{4})ë…„\s*(\d{1,2})ì›”$', '-'),  # YYYYë…„ Mì›”
            (r'^(\d{4})\s+(\d{1,2})$', '-')  # YYYY M (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
        ]
        
        for pattern, separator in date_patterns:
            match = re.match(pattern, header_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)  # ì›”ì„ 2ìë¦¬ë¡œ íŒ¨ë”©
                formatted_date = f"{year}-{month}-01"
                # ë¡œê·¸ ê°„ì†Œí™”: ì²« ë²ˆì§¸ ë³€í™˜ë§Œ ë¡œê·¸ ì¶œë ¥
                if not hasattr(self, '_date_conversion_logged'):
                    log(f"        - ë‚ ì§œ í—¤ë” ë³€í™˜ ì˜ˆì‹œ: {header_str} -> {formatted_date}")
                    self._date_conversion_logged = True
                return formatted_date
        
        # ìˆ«ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš° ì²˜ë¦¬
        if header_str.isdigit():
            # 4ìë¦¬ ìˆ«ìëŠ” ì—°ë„ë¡œ ì²˜ë¦¬ (1ì›”ë¡œ ì„¤ì •)
            if len(header_str) == 4 and 1900 <= int(header_str) <= 2100:
                formatted_date = f"{header_str}-01-01"
                return formatted_date
            # 1-2ìë¦¬ ìˆ«ìëŠ” ì›”ë¡œ ì²˜ë¦¬ (í˜„ì¬ ì—°ë„ ì‚¬ìš©)
            elif len(header_str) <= 2 and 1 <= int(header_str) <= 12:
                current_year = datetime.now().year
                month = header_str.zfill(2)
                formatted_date = f"{current_year}-{month}-01"
                return formatted_date
        
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜ (ë¡œê·¸ ìƒëµ)
        return header_text

    def _is_valid_region_name(self, region_name):
        """ì§€ì—­ëª… ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜ - 'ì„œìš¸1', 'ë¶€ì‚°2' í˜•íƒœ í—ˆìš©"""
        if not region_name or not region_name.strip():
            return False

        region_str = region_name.strip()
        
        # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°
        if not region_str or region_str.isspace():
            return False

        # í•œêµ­ ì§€ì—­ëª… íŒ¨í„´ í™•ì¸ (ë” í¬ê´„ì ìœ¼ë¡œ)
        valid_regions = [
            'ê°•ì›', 'ê²½ê¸°', 'ê²½ë‚¨', 'ê²½ë¶', 'ê´‘ì£¼', 'ëŒ€êµ¬', 'ëŒ€ì „', 'ë¶€ì‚°',
            'ì„œìš¸', 'ì„¸ì¢…', 'ìš¸ì‚°', 'ì¸ì²œ', 'ì „ë‚¨', 'ì „ë¶', 'ì œì£¼', 'ì¶©ë‚¨', 'ì¶©ë¶',
            'ìˆ˜ì›', 'ì„±ë‚¨', 'ì¶˜ì²œ'  # ì¶”ê°€ ì§€ì—­ëª…
        ]

        # ìˆ«ìê°€ í¬í•¨ëœ ì§€ì—­ëª…ë„ í—ˆìš© (ì˜ˆ: ì„œìš¸1, ë¶€ì‚°2)
        # ìƒˆë¡œìš´ íŒ¨í„´: ì§€ì—­ëª… + ìˆ«ì (ì„œìš¸1, ë¶€ì‚°2 ë“±)
        for region in valid_regions:
            if region in region_str:
                # ì§€ì—­ëª…ì´ í¬í•¨ë˜ì–´ ìˆê³ , ìˆ«ìê°€ ë’¤ì— ì˜¤ëŠ” íŒ¨í„´ í—ˆìš©
                pattern = f"{region}\\d*$"
                if re.search(pattern, region_str):
                    return True
                # ê¸°ì¡´ íŒ¨í„´ë„ í—ˆìš© (ì§€ì—­ëª…ë§Œ)
                if region_str == region:
                    return True

        # ë‚ ì§œ íŒ¨í„´ì´ í¬í•¨ëœ ê²½ìš° ì§€ì—­ëª…ì´ ì•„ë‹˜ (ë” ì—„ê²©í•˜ê²Œ)
        date_patterns = [
            r'\d{4}[./-]\d{1,2}',  # YYYY.M, YYYY/M, YYYY-M
            r'\d{4}\.\s*\d{1,2}',  # YYYY. M (ê³µë°± í¬í•¨)
            r'^\d{4}$',  # ì—°ë„ë§Œ
            r'^\d{1,2}$',  # ì›”ë§Œ
            r'^\d{4}ë…„',  # YYYYë…„
            r'^\d{1,2}ì›”'  # Mì›”
        ]
        
        for pattern in date_patterns:
            if re.search(pattern, region_str):
                # ë¡œê·¸ ìµœì í™”: ë‚ ì§œ íŒ¨í„´ ì œì™¸ ë¡œê·¸ ìƒëµ
                return False

        # ê¸°íƒ€ ì˜ëª»ëœ ê°’ ì²´í¬ (ë” í¬ê´„ì ìœ¼ë¡œ)
        invalid_patterns = [
            'êµ¬ë¶„', 'í‰ê· ', 'ì „êµ­', 'ê¸°ì¤€', 'í•©ê³„', 'ì´ê³„', 'ì†Œê³„',
            'ë‹¨ìœ„', 'ì›', 'ì²œì›', 'ë§Œì›', 'ì–µì›',
            'ë…„', 'ì›”', 'ì¼', 'ê¸°ê°„',
            '-', '/', '\\', '|', '+', '='
        ]
        
        for pattern in invalid_patterns:
            if pattern in region_str:
                # ë¡œê·¸ ìµœì í™”: ì˜ëª»ëœ íŒ¨í„´ ì œì™¸ ë¡œê·¸ ìƒëµ
                return False
        
        # ìˆ«ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš° ì œì™¸
        if region_str.isdigit():
            return False
        
        # íŠ¹ìˆ˜ë¬¸ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš° ì œì™¸
        if not re.search(r'[ê°€-í£a-zA-Z]', region_str):
            return False

        return True

    def _is_valid_date_value(self, date_value):
        """ë‚ ì§œ ê°’ì´ ìœ íš¨í•œì§€ í™•ì¸"""
        if date_value is None:
            return False

        # datetime ê°ì²´ì¸ ê²½ìš° ìœ íš¨
        if hasattr(date_value, 'strftime'):
            return True

        # ë¬¸ìì—´ì¸ ê²½ìš° ê²€ì¦
        if isinstance(date_value, str):
            # ë™ê·¸ë¼ë¯¸ ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ ê²½ìš° ì œì™¸
            circle_chars = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤', 'â‘¥', 'â‘¦', 'â‘§', 'â‘¨', 'â‘©']
            if any(char in date_value for char in circle_chars):
                return False

            # 'ê°€ê²©' ë“±ì˜ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²½ìš° ì œì™¸
            if any(char in date_value for char in ['ê°€', 'ê²©', 'êµ¬', 'ë¶„']):
                return False

            # 'YYYY-MM-DD' í˜•íƒœ í™•ì¸
            if re.match(r'^\d{4}-\d{2}-\d{2}$', date_value.strip()):
                return True

            # 'YYYY. M' í˜•íƒœ í™•ì¸
            date_pattern = r'^\d{4}\.\s*\d{1,2}$'
            if re.match(date_pattern, date_value.strip()):
                return True

        return False

    def _is_valid_price(self, price_str):
        """ê°€ê²© ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        if not price_str:
            return False
        
        price_stripped = price_str.strip()
        if (not price_stripped or 
            price_stripped == '-' or 
            price_stripped == ''):
            return False
            
        clean_price = price_stripped.replace(',', '')
        try:
            float(clean_price)
            return True
        except ValueError:
            return False

    async def _process_specs_parallel(self, spec_list, raw_item_data,
                                     major_name, middle_name, sub_name,
                                     sub_url):
        """ì—¬ëŸ¬ ê·œê²©ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ë©”ì„œë“œ"""
        semaphore = asyncio.Semaphore(2)  # ìµœëŒ€ 2ê°œ ë™ì‹œ ì²˜ë¦¬

        async def process_spec_with_new_page(spec):
            async with semaphore:
                try:
                    # ìƒˆë¡œìš´ í˜ì´ì§€ ìƒì„±
                    new_page = await self.context.new_page()
                    base_url = "https://www.kpi.or.kr/www/price/"
                    await new_page.goto(f"{base_url}{sub_url}")
                    await new_page.wait_for_load_state(
                        'networkidle', timeout=60000)
                    await new_page.wait_for_selector(
                        'body', timeout=5000)

                    # 'ë¬¼ê°€ì¶”ì´ ë³´ê¸°' íƒ­ìœ¼ë¡œ ì´ë™ (ì¬ì‹œë„ ë¡œì§)
                    for retry in range(3):
                        try:
                            # íƒ­ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
                            await new_page.wait_for_selector('a:has-text("ë¬¼ê°€ì¶”ì´ ë³´ê¸°")', timeout=15000)
                            
                            link_name = 'ë¬¼ê°€ì¶”ì´ ë³´ê¸°'
                            link_locator = new_page.get_by_role(
                                'link', name=link_name)
                            await link_locator.click(timeout=30000)
                            await new_page.wait_for_selector(
                                "#ITEM_SPEC_CD", timeout=30000)
                            break
                        except Exception as e:
                            if retry == 2:
                                raise e
                            log(f"ë¬¼ê°€ì¶”ì´ ë³´ê¸° íƒ­ í´ë¦­ ì¬ì‹œë„ {retry + 1}/3: {e}", "WARNING")
                            await new_page.reload()
                            await new_page.wait_for_load_state(
                                'domcontentloaded', timeout=10000)
                            await new_page.wait_for_load_state(
                                'networkidle', timeout=30000)

                    # ì„ì‹œ ë°ì´í„° êµ¬ì¡°
                    temp_data = {
                        'major_category_name': major_name,
                        'middle_category_name': middle_name,
                        'sub_category_name': sub_name,
                        'spec_data': []
                    }

                    # ê·œê²© ì²˜ë¦¬
                    await self._process_single_spec(new_page, spec, temp_data)

                    await new_page.close()
                    return temp_data['spec_data']

                except Exception as e:
                    error_msg = (f"    - ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ê·œê²© '{spec['name']}' ì˜¤ë¥˜ "
                                f"[ëŒ€ë¶„ë¥˜: {major_name}, ì¤‘ë¶„ë¥˜: {middle_name}, "
                                f"ì†Œë¶„ë¥˜: {sub_name}]: {str(e)}")
                    log(error_msg)
                    return []

        # ëª¨ë“  ê·œê²©ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
        # ëª¨ë“  ê·œê²©ì— ëŒ€í•œ ë³‘ë ¬ ì²˜ë¦¬ íƒœìŠ¤í¬ ìƒì„±
        tasks = [process_spec_with_new_page(spec)
                 for spec in spec_list]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ë³‘í•©
        for result in results:
            if isinstance(result, list) and result:
                raw_item_data['spec_data'].extend(result)

    async def _process_single_spec(self, page, spec, raw_item_data):
        """ë‹¨ì¼ ê·œê²©ì— ëŒ€í•œ ë°ì´í„° ì²˜ë¦¬"""
        spec_value = spec['value']
        spec_name = spec['name']
        log(f"    - ê·œê²©: '{spec_name}' ì¡°íšŒ ì¤‘...")

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # ê·œê²© ì„ íƒ
                # ê·œê²© ì„ íƒ
                spec_locator = page.locator('#ITEM_SPEC_CD')
                await spec_locator.select_option(value=spec_value)
                await page.wait_for_load_state(
                    'networkidle', timeout=3000)

                # ê¸°ê°„ ì„ íƒ
                year_locator = page.locator('#DATA_YEAR_F')
                await year_locator.select_option(value=self.start_year)
                month_locator = page.locator('#DATA_MONTH_F')
                await month_locator.select_option(
                    value=self.start_month)
                await page.wait_for_load_state(
                    'networkidle', timeout=3000)

                # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
                search_selector = 'form[name="sForm"] input[type="image"]'
                search_button = page.locator(search_selector)
                await search_button.click(timeout=10000)
                await page.wait_for_load_state(
                    'networkidle', timeout=15000)
                break

            except Exception as e:
                if attempt < max_retries - 1:
                    attempt_num = attempt + 1
                    log(f"    - ê·œê²© '{spec_name}' ì‹œë„ {attempt_num} "
                        f"ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘...")
                    await page.wait_for_timeout(1000)
                    continue
                else:
                    log(f"    - ê·œê²© '{spec_name}' ìµœì¢… ì‹¤íŒ¨: "
                        f"{str(e)}")
                    return

        # ë°ì´í„° í…Œì´ë¸” íŒŒì‹±
        try:
            await page.wait_for_selector(
            "#priceTrendDataArea tr", timeout=10000)

            # ì „ì²´ í…Œì´ë¸” HTMLì„ ë¡œê·¸ë¡œ ì¶œë ¥í•´ì„œ êµ¬ì¡° í™•ì¸
            table_html = await page.locator("#priceTrendDataArea").inner_html()
            log(f"    - ê·œê²© '{spec_name}': í…Œì´ë¸” HTML êµ¬ì¡°:\n{table_html[:500]}...")

            header_elements = await page.locator(
            "#priceTrendDataArea th").all()
            if not header_elements:
                log(f"    - ê·œê²© '{spec_name}': ë°ì´í„° í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            # ì²« ë²ˆì§¸ í—¤ë”ëŠ” 'êµ¬ë¶„'ì´ë¯€ë¡œ ì œì™¸
            dates = [await h.inner_text() for h in header_elements[1:]]
            log(f"    - ê·œê²© '{spec_name}': í—¤ë” ë°ì´í„° = {dates}")

            # ì²« ë²ˆì§¸ ì§€ì—­ ë°ì´í„° í–‰ë§Œ ì¶”ì¶œ (ì˜ˆ: 'ì„œâ‘ ìš¸')
            data_rows = await page.locator("#priceTrendDataArea tr").all()
            log(f"    - ê·œê²© '{spec_name}': ì´ {len(data_rows)}ê°œ í–‰ ë°œê²¬")
            if len(data_rows) < 2:
                log(f"    - ê·œê²© '{spec_name}': ë°ì´í„° í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            first_row_tds = await data_rows[1].locator("td").all()
            if not first_row_tds:
                log(f"    - ê·œê²© '{spec_name}': ë°ì´í„° ì…€ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            region = await first_row_tds[0].inner_text()
            prices = [await td.inner_text() for td in first_row_tds[1:]]
            log(f"    - ê·œê²© '{spec_name}': ì§€ì—­ = {region}, "
                f"ê°€ê²© ë°ì´í„° = {prices}")

            # í—¤ë” ì •ë³´ ì¶”ì¶œ (í…Œì´ë¸” êµ¬ì¡° íŒŒì•…ìš©)
            header_cells = await data_rows[0].locator("th").all()
            headers = []
            for i in range(1, len(header_cells)):  # ì²« ë²ˆì§¸ ì»¬ëŸ¼(êµ¬ë¶„) ì œì™¸
                header_text = await header_cells[i].inner_text()
                # ë™ê·¸ë¼ë¯¸ ìˆ«ìë¥¼ ì¼ë°˜ ìˆ«ìë¡œ ë³€í™˜ (â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘© ë“± -> 1,2,3)
                circle_to_num = {
                    'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5',
                    'â‘¥': '6', 'â‘¦': '7', 'â‘§': '8', 'â‘¨': '9', 'â‘©': '10'
                }
                cleaned_header = header_text.strip()
                for circle, num in circle_to_num.items():
                    cleaned_header = cleaned_header.replace(circle, num)

                # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                # (YYYY.M ë˜ëŠ” YYYY. M í˜•íƒœë§Œ í—ˆìš©)
                if self._is_valid_date_header(cleaned_header):
                    headers.append(cleaned_header)
                else:
                    log(f"    - ì˜ëª»ëœ ë‚ ì§œ í—¤ë” ì œì™¸: "
                        f"'{cleaned_header}' (ì›ë³¸: '{header_text}')")

            log(f"    - ê·œê²© '{spec_name}': "
                f"í—¤ë” ë°ì´í„° = {headers}")

            price_list = []
            # í…Œì´ë¸” êµ¬ì¡° ë¶„ì„: í—¤ë”ê°€ ë‚ ì§œì´ê³  í–‰ì´ ì§€ì—­ë³„ ë°ì´í„°ì¸ êµ¬ì¡°
            # ê° ì§€ì—­(í–‰)ì— ëŒ€í•´ ì²˜ë¦¬
            # í—¤ë” ì œì™¸í•˜ê³  ëª¨ë“  í–‰ ì²˜ë¦¬
            for i in range(1, len(data_rows)):
                try:
                    row_tds = await data_rows[i].locator("td").all()
                    if len(row_tds) >= 2:
                        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì§€ì—­ëª…
                        region_str = await row_tds[0].inner_text()
                        # ë™ê·¸ë¼ë¯¸ ìˆ«ìë¥¼ ì¼ë°˜ ìˆ«ìë¡œ ë³€í™˜ (â‘ â‘¡â‘¢ ë“± -> 1,2,3)
                        circle_to_num = {
                            'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4',
                            'â‘¤': '5', 'â‘¥': '6', 'â‘¦': '7', 'â‘§': '8',
                            'â‘¨': '9', 'â‘©': '10'
                        }
                        clean_region = region_str.strip()
                        for circle, num in circle_to_num.items():
                            clean_region = clean_region.replace(
                                circle, num)

                        # ê° ë‚ ì§œë³„ ê°€ê²© ì²˜ë¦¬
                        for j, date_header in enumerate(headers):
                            if j + 1 < len(row_tds):
                                price_str = await row_tds[j + 1].inner_text()
                                # ê°€ê²© ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ê°•í™”
                                price_stripped = price_str.strip()
                                if price_stripped and price_stripped != '-':
                                    # ì‰¼í‘œê°€ í¬í•¨ëœ ìˆ«ìì¸ì§€ í™•ì¸
                                    clean_price = price_stripped.replace(
                                        ',', '')
                                    is_valid_price = (
                                        clean_price.isdigit() and
                                        int(clean_price) > 0)
                                    if is_valid_price:
                                        # ë‚ ì§œ íŒŒì‹± (YYYY. M í˜•íƒœ)
                                        try:
                                            is_valid_header = (
                                                self._is_valid_date_header(
                                                    date_header))
                                            if is_valid_header:
                                                year_month = (
                                                    date_header.strip()
                                                    .replace(' ', ''))
                                                if '.' in year_month:
                                                    year, month = year_month.split('.')
                                                    date_obj = datetime(
                                                        int(year),
                                                        int(month), 1)
                                                    price_data = {
                                                        'date': date_obj,
                                                        'region': clean_region,
                                                        'price': price_str.strip()
                                                    }
                                                    price_list.append(price_data)
                                                    # ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì¶”ê°€ ë¡œê·¸
                                                    log(
                                                        f"    - ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì¶”ê°€: "
                                                        f"{clean_region} "
                                                        f"({date_header}) = "
                                                        f"{price_str.strip()}")
                                            else:
                                                # ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ì œì™¸ ë¡œê·¸
                                                log(
                                                    f"    - ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ì œì™¸: "
                                                    f"{date_header}")
                                        except Exception as date_parse_error:
                                            # ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜ ë¡œê·¸
                                            log(
                                                f"    - ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: "
                                                f"{date_header} - "
                                                f"{str(date_parse_error)}")
                except Exception as row_error:
                    # í–‰ íŒŒì‹± ì˜¤ë¥˜ ë¡œê·¸
                    log(f"    - í–‰ {i} íŒŒì‹± ì˜¤ë¥˜: {str(row_error)}")
                    continue

            if price_list:
                raw_item_data['spec_data'].append({
                    'specification_name': spec_name,
                    'prices': price_list
                })
                log(f"    - ê·œê²© '{spec_name}': {len(price_list)}ê°œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            else:
                log(f"    - ê·œê²© '{spec_name}': ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì—†ìŒ")

        except Exception as e:
            log(f"    - ê·œê²© '{spec_name}' ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return


# --- 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
# <<< íŒŒì¼ ë§¨ ì•„ë˜ ë¶€ë¶„ì„ ì´ ì½”ë“œë¡œ ì „ì²´ êµì²´ (5/5) >>>

async def main():
    """ë©”ì¸ ì‹¤í–‰ ë¡œì§: ëª…ë ¹í–‰ ì¸ì íŒŒì‹± ë° í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
    # GitHub Actions í™˜ê²½ì— ìµœì í™”ëœ ì¸ì íŒŒì‹± ë°©ì‹
    # ì˜ˆ: --major="ê³µí†µìì¬"
    args = {arg.split('=')[0].strip('-'): arg.split('=')[1].strip('"\'') for arg in sys.argv[1:] if '=' in arg}
    
    target_major = args.get('major')
    start_year = args.get('start-year', '2020')
    start_month = args.get('start-month', '01').zfill(2)

    # --major ì¸ìê°€ ì—†ìœ¼ë©´ ì „ì²´ ëŒ€ë¶„ë¥˜ í¬ë¡¤ë§
    if not target_major:
        log("--major ì¸ìê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ëŒ€ë¶„ë¥˜ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.", "INFO")
        all_major_categories = list(KpiCrawler.INCLUSION_LIST.keys())
        log(f"í¬ë¡¤ë§í•  ëŒ€ë¶„ë¥˜: {all_major_categories}", "INFO")
        
        for major in all_major_categories:
            log(f"=== {major} í¬ë¡¤ë§ ì‹œì‘ ===", "SUMMARY")
            crawler = KpiCrawler(target_major=major, start_year=start_year, start_month=start_month)
            await crawler.run()
            log(f"ğŸŸ¢ {major} í¬ë¡¤ë§ ì™„ë£Œ", "SUCCESS")
        
        log("ğŸŸ¢ ì „ì²´ ëŒ€ë¶„ë¥˜ í¬ë¡¤ë§ ì™„ë£Œ", "SUCCESS")
        return

    log(f"'{target_major}' ëŒ€ë¶„ë¥˜ í¬ë¡¤ë§ ì‹œì‘ (ì‹œì‘ ë‚ ì§œ: {start_year}-{start_month})", "SUMMARY")
    crawler = KpiCrawler(target_major=target_major, start_year=start_year, start_month=start_month)
    await crawler.run()
    log(f"ğŸŸ¢ '{target_major}' ëŒ€ë¶„ë¥˜ í¬ë¡¤ë§ ì™„ë£Œ.", "SUCCESS")


if __name__ == "__main__":
    running_crawlers = check_running_crawler()
    if running_crawlers:
        log(f"ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ í¬ë¡¤ëŸ¬ {len(running_crawlers)}ê°œ ë°œê²¬. ê¸°ì¡´ í¬ë¡¤ëŸ¬ ì™„ë£Œ í›„ ì¬ì‹¤í–‰í•˜ì„¸ìš”.", "ERROR")
        sys.exit(1)
    
    asyncio.run(main())